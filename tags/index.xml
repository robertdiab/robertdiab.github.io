

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Topics on Robert Diab</title>
    <link>https://www.robertdiab.ca/tags/</link>
    <description>Recent content in Topics on Robert Diab</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 27 Dec 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://www.robertdiab.ca/tags/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Powers in the new Cyber Security Act are invasive — but do they violate the Charter?</title>
      <link>https://www.robertdiab.ca/posts/bill-c8/</link>
      <pubDate>Sat, 27 Dec 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.robertdiab.ca/posts/bill-c8/</guid>
      <description>&lt;p&gt;&lt;em&gt;Critics of the bill are right to be concerned, so why the curious silence in the government’s Charter Statement?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Shortly after tabling bill C-2 in June, which I’ve written a &lt;a href=&#34;https://robertdiab.substack.com/p/bill-c-2-backgrounder-the-missing&#34;&gt;few&lt;/a&gt; &lt;a href=&#34;https://robertdiab.substack.com/p/five-ways-to-fix-bill-c-2-and-better&#34;&gt;posts&lt;/a&gt; about, the government tabled &lt;a href=&#34;https://www.parl.ca/DocumentViewer/en/45-1/bill/C-8/first-reading&#34;&gt;Bill C-8&lt;/a&gt;, the &lt;em&gt;Cyber Security Act&lt;/em&gt;. It too raises serious concerns about privacy but hasn’t attracted nearly as much attention.&lt;/p&gt;
&lt;p&gt;In broad terms, the bill does two things. It amends telecommunications law to allow the Minister of Industry to order telcos like Shaw and Telus to make changes to their systems to bolster security and investigate breaches. It also creates a new framework for protecting “critical cyber systems” that support infrastructure like pipelines, banking networks, and commercial telecommunications.&lt;/p&gt;
&lt;p&gt;With the bill now at second reading, digital rights advocates &lt;a href=&#34;https://citizenlab.ca/2025/10/submission-to-the-standing-committee-on-public-safety-and-national-security-of-bill-c-8/&#34;&gt;have&lt;/a&gt; &lt;a href=&#34;https://ccla.org/wp-content/uploads/2025/12/2025.12.15-CCLA-Bill.C8.SECU_.Brief-FINAL.pdf&#34;&gt;argued&lt;/a&gt; before a standing committee that portions of the first part of the bill are especially concerning and likely violate section 8 of the &lt;em&gt;Charter&lt;/em&gt;, which guarantees the right to be secure against unreasonable search or seizure.&lt;/p&gt;
&lt;p&gt;The nub of the issue is the power in bill C-8 to order a telco like Shaw to do something that might involve the incidental collection of personal information or its disclosure to an agency like the Communications Security Establishment (&lt;a href=&#34;https://www.cse-cst.gc.ca/en&#34;&gt;CSE&lt;/a&gt;) investigating a cyberbreach.&lt;/p&gt;
&lt;p&gt;To make this more vivid, consider the testimony of Simon Noël, Intelligence Commissioner of Canada, before the committee in October, where &lt;a href=&#34;https://www.ourcommons.ca/Content/Committee/451/SECU/Evidence/EV13724995/SECUEV10-E.PDF&#34;&gt;he said&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In my experience as IC—with over three years and 45 decisions rendered—for the CSE to analyze and understand a cyber-incident, it must have access to information about the incident. There may be situations where this information is only technical in nature and sharing it with the CSE raises no privacy concerns, as you were told when you met with other witnesses. However, to fully understand the cyber-incident, other situations may require the CSE to have access to information, including technical information, for which Canadians have a reasonable expectation of privacy. I&amp;rsquo;ve seen it. … I agree that it’s technical information, but I also know that if you want a positive result on an incident of such importance, they need to go into the content. I’ve seen it in every cyber-operation I’ve been involved in.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Critics of the bill &lt;a href=&#34;https://citizenlab.ca/2025/10/submission-to-the-standing-committee-on-public-safety-and-national-security-of-bill-c-8/&#34;&gt;point&lt;/a&gt; &lt;a href=&#34;https://ccla.org/wp-content/uploads/2025/12/2025.12.15-CCLA-Bill.C8.SECU_.Brief-FINAL.pdf&#34;&gt;out&lt;/a&gt; important gaps in C-8 that fail to address the Commissioner’s concerns. They note features of the bill that might even make problems worse.&lt;/p&gt;
&lt;h3 id=&#34;power-without-accountability&#34;&gt;Power without accountability?&lt;/h3&gt;
&lt;p&gt;One section of the bill allows the government to order a telco to do any “specified thing” considered on reasonable grounds to be necessary for securing Canada’s telecommunications networks. Another prevents ordering a telco from intercepting “private communications” as this is defined in the wiretap sections of the &lt;em&gt;Criminal Code&lt;/em&gt;. But this, the critics say, wouldn’t preclude an order allowing for the collection of metadata — for example, the date and time I sent emails to a certain address, called certain numbers, or even visited certain websites. Information we know to be highly sensitive.&lt;/p&gt;
&lt;p&gt;The Minister can also require a telco to “provide… any information” the Minister has reasonable grounds to believe is “relevant” to making a security-related order. This info can be shared with a host of government agencies, including Foreign Affairs, CSIS, the CSE, or with a foreign government — though it must be treated as confidential and shared only for the purpose of “securing the Canadian telecommunications system or the telecommunications system of a foreign state, including against the threat of interference, manipulation or disruption.”&lt;/p&gt;
&lt;p&gt;Rights advocates &lt;a href=&#34;https://citizenlab.ca/2025/10/submission-to-the-standing-committee-on-public-safety-and-national-security-of-bill-c-8/&#34;&gt;argue&lt;/a&gt; that the power to compel “any information” — which might include metadata — amounts to an unreasonable search under section 8 of the &lt;em&gt;Charter&lt;/em&gt; because it doesn’t require a warrant. It should require one, they argue, on the standard of necessity and proportionality, if not on probable grounds.&lt;/p&gt;
&lt;p&gt;They also &lt;a href=&#34;https://ccla.org/wp-content/uploads/2025/12/2025.12.15-CCLA-Bill.C8.SECU_.Brief-FINAL.pdf&#34;&gt;flag&lt;/a&gt; a host of other concerns. The bill contemplates imposing ‘deep packet inspection’ capabilities onto telcos, enabling the &lt;em&gt;content&lt;/em&gt; of our communications to be scanned. It’s not clear that the bill rules out compelling decryption. It also permits orders cutting off a person’s internet access without explanation, and blocking access to websites without public notice. It contains limited review provisions. Much that is less than ideal.&lt;/p&gt;
&lt;h3 id=&#34;but-does-it-engage-the-charter&#34;&gt;But does it engage the Charter?&lt;/h3&gt;
&lt;p&gt;In its &lt;a href=&#34;https://www.justice.gc.ca/eng/csj-sjc/pl/charter-charte/c8_2.html&#34;&gt;Charter Statement&lt;/a&gt; for Bill C-8, the government is curiously silent on the section 8 implications of incidentally gathering and sharing metadata, let alone the possible scanning of content. The Statement deals only with a search or seizure carried out against Telus or Shaw to ensure compliance with a ministerial order.&lt;/p&gt;
&lt;p&gt;I agree with critics of the bill that the parts of it they flag would likely violate section 8. But in the rest of this post, I want to address an argument the government might make in defence of these powers under the &lt;em&gt;Charter&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;As Kate Robertson of CitizenLab has noted in relation to the metadata that could be gathered under C-8, “there is no reasonable dispute that these information sources carry significant privacy interests.”&lt;/p&gt;
&lt;p&gt;But does our privacy interest in this info extend to measures the government takes &lt;em&gt;strictly&lt;/em&gt; to secure the system from cyber attacks?&lt;/p&gt;
&lt;p&gt;Put differently: could the government argue that powers allowing the incidental gathering and sharing of personal info are constitutional because they do not target individuals for an investigative purpose?&lt;/p&gt;
&lt;h3 id=&#34;when-is-section-8-engaged&#34;&gt;When &lt;em&gt;is&lt;/em&gt; section 8 engaged?&lt;/h3&gt;
&lt;p&gt;Section 8 is clearly engaged when a state actor interferes with a reasonable expectation of privacy for an investigative purpose related to a possible criminal or regulatory offence. This is most of the Supreme Court of Canada’s case law on section 8.&lt;/p&gt;
&lt;p&gt;But in many cases, the Court decides whether there has been an interference with a privacy interest — and thus a search or seizure — by first distinguishing between things to which we did or didn’t implicitly consent. And this is where the investigative purpose, or lack thereof, becomes important.&lt;/p&gt;
&lt;p&gt;The most notable example might be &lt;a href=&#34;https://canlii.ca/t/1frf4&#34;&gt;&lt;em&gt;R v Evans&lt;/em&gt;&lt;/a&gt;. Police knocked on Evans’ front door with the intention of seeing if they could smell the odour of marijuana emanating from inside. Because they had this intent from the outset, police exceeded the limited waiver of privacy entailed in the implied invitation to knock and thus carried out a search.&lt;/p&gt;
&lt;p&gt;Put more generally, courts say that any state interference with privacy constitutes a search under section 8, but often find that things done for a non-investigative purpose don’t entail an interference. The thing was either not private (because you implicitly consented to it being done) or the state action didn’t amount to an intrusion.&lt;/p&gt;
&lt;p&gt;In their submissions to Parliament, rights advocates are correct to assert that parts of the bill may violate section 8 because they give rise to state action that interferes with something over which we have a reasonable expectation of privacy (i.e., collecting, inspecting, sharing our metadata).&lt;/p&gt;
&lt;p&gt;But could a court find that C-8’s privacy invasive measures &lt;em&gt;do not&lt;/em&gt; amount to a search or seizure by taking the view that they don’t in fact “interfere” with our privacy — given the law’s non-investigative purpose?&lt;/p&gt;
&lt;h3 id=&#34;constitutional-privacy-beyond-investigation&#34;&gt;Constitutional privacy beyond investigation&lt;/h3&gt;
&lt;p&gt;The state often gathers our private information without engaging section 8 because it does so without an investigative or audit-like purpose: for example, in the delivery of health care or the administration of the income-tax system. Courts would hold in these cases that there’s no search or seizure because the collection doesn’t interfere with a reasonable privacy interest. You either consent to have your medical info gathered or it isn’t reasonable to assert a privacy interest against the state in info about your income for tax reporting purposes.&lt;/p&gt;
&lt;p&gt;The key point is this: whether the info is private under section 8, or whether its collection amounts to an interference, depends on the &lt;em&gt;purpose&lt;/em&gt; for which the state acts. Something will retain a reasonable privacy interest (our blood, our data) if the state acts with an investigative or audit-like purpose — if the state is seeking to &lt;em&gt;learn something&lt;/em&gt; about a person to hold them to account for a possible breach of the law. But where the state acts for some other purpose, courts consistently say either that it wasn’t private or it wasn’t an interference.&lt;/p&gt;
&lt;p&gt;Two quick examples.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;https://canlii.ca/t/1ftc6&#34;&gt;&lt;em&gt;R v Dyment&lt;/em&gt;&lt;/a&gt;, a doctor took a blood sample from a patient without his knowledge or consent following a car accident. A majority held that the patient had impliedly consented to a sample being taken for medical purposes and for those alone. It became a seizure under section 8 when the doctor gave the sample to a police officer who received it for an investigative purpose.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://canlii.ca/t/ft969&#34;&gt;&lt;em&gt;R v Cole&lt;/em&gt;&lt;/a&gt; (2012) presents a closer parallel to Bill C-8. A school board technician found pictures of a student while conducting maintenance on a teacher’s work-issued laptop, and turned the computer over to the principal who turned it over to police. Justice Fish, for the majority, made the broad statement that&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As Mr. Cole had a reasonable expectation of privacy in his Internet browsing history and the informational content of his work-issued laptop, any non-consensual examination by the state was a “search”; and any taking, a “seizure”.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yet, as Justice Fish notes, Cole conceded that the “initial inspection of the laptop by the school technician in the context of routine maintenance activities… did not breach his s. 8 rights.” The Court of Appeal for Ontario &lt;a href=&#34;https://canlii.ca/t/fkmxr&#34;&gt;explained why&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;…the technician was accessing the appellant’s laptop for the limited purpose of maintaining the network. The technician found the images in the course of his legitimate access to the computer. Therefore, the appellant had no expectation of privacy with respect to this limited type of action. Since there was no reasonable expectation of privacy with respect to the technician’s actions, s. 8 of the Charter was not engaged.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It wasn’t until the tech handed the laptop over to the principal — who examined it with an investigative purpose — that Cole’s rights under section 8 were engaged.&lt;/p&gt;
&lt;h3 id=&#34;what-about-cybersecurity&#34;&gt;What about cybersecurity?&lt;/h3&gt;
&lt;p&gt;I think a court would consider the incidental collection of metadata or even scanning for deep packet inspection to be an interference with our private information — if it were to find that our info was private against &lt;em&gt;this kind&lt;/em&gt; of intrusion. The big question here is whether a court would treat cybersecurity measures as akin to the “routine maintenance activities” in &lt;em&gt;Cole.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Would courts assume that we implicitly consent to such measures, or that it is unreasonable to assert a privacy interest against them, because the collection and sharing are merely incidental to safeguarding the system?&lt;/p&gt;
&lt;p&gt;To be clear, the moment personal info gathered under C-8 is used for an investigative purpose against an individual, section 8 would be engaged. We neither consent to this use nor reasonably expect it to occur.&lt;/p&gt;
&lt;p&gt;Even so, I agree with critics of the bill that incidental collection and sharing of personal info here would still violate section 8. The reason is simple: the powers in C-8 to share info among domestic agencies and foreign governments are so broad — despite the need that it be kept confidential and used only for the purpose of cybersecurity — that it’s impossible to draw a principled line between investigative and non-investigative use.&lt;/p&gt;
&lt;p&gt;If info uncovered in a cybersecurity were later used to prosecute a hacker, was the audit about securing the system or investigating crime? The bill offers no clear answer.&lt;/p&gt;
&lt;p&gt;I also agree with another argument critics of the bill — including the Privacy Commissioner of Canada — make. The powers in C-8 at issue conflict with the letter, if not the spirit, of quasi-constitutional provisions in privacy legislation such as PIPEDA, the CSE Act, the CSIS Act. These laws impose important safeguards that are notably absent here. Bill C-8 should be amended to bring it into closer conformity with those protections, if not with the &lt;em&gt;Charter&lt;/em&gt; itself.&lt;/p&gt;
&lt;p&gt;Happy holidays!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Five ways to fix bill C-2 – and better protect our privacy</title>
      <link>https://www.robertdiab.ca/posts/fixing-c2/</link>
      <pubDate>Wed, 17 Dec 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.robertdiab.ca/posts/fixing-c2/</guid>
      <description>&lt;p&gt;As it inches toward a majority in Parliament, the Liberal government is signaling its intention to move ahead with the controversial parts of the &lt;em&gt;Strong Borders Act&lt;/em&gt; it chose to shelve back in October — in response to strong opposition from the other parties.&lt;/p&gt;
&lt;p&gt;I’ve written about the various privacy-invasive powers in the bill briefly &lt;a href=&#34;https://www.robertdiab.ca/posts/strong-borders-search/&#34;&gt;here&lt;/a&gt;, and in more detail &lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5363319&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Last week I had the pleasure of attending a roundtable with the Honourable Minister of Public Safety, Gary Anandasangaree, who asked for ideas about how to improve the bill.&lt;/p&gt;
&lt;p&gt;Here are five:&lt;/p&gt;
&lt;h3 id=&#34;1-narrow-the-new-information-demand-power-to-big-telcos-and-only-to-confirming-an-account&#34;&gt;1. &lt;em&gt;Narrow the new “information demand” power to big telcos and only to confirming an account&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The bill would amend the &lt;em&gt;Criminal Code&lt;/em&gt; to allow police, without a warrant, to demand from any person who “provides services to the public” — a doctor, psychiatrist, or dating app — details about the services they delivered to a particular client or account holder, such as where, when, and how often they provided the service.&lt;/p&gt;
&lt;p&gt;The Supreme Court of Canada, hearing a &lt;em&gt;Charter&lt;/em&gt; challenge to this, would likely find the scope of this power to be too broad, and the privacy interest it engages to be too high, to strike a reasonable balance between law enforcement and personal privacy. I would think anything less than a warrant on probable grounds would be a tough sell here.&lt;/p&gt;
&lt;p&gt;Police say they want this power to be able to quickly ask Shaw, Telus, or Rogers to confirm whether an IP address of interest is connected to an account they host. If that’s what the police want, then why not just narrow this power down to that? Make it applicable only to large electronic service providers and only allow police to demand a yes or no answer to the question: does the user with this IP address have an account with you?&lt;/p&gt;
&lt;p&gt;That, on reasonable suspicion alone, might fly.&lt;/p&gt;
&lt;h3 id=&#34;2-narrow-the-scope-of-the-new-subscriber-id-production-order-andor-raise-the-standard&#34;&gt;2. &lt;em&gt;Narrow the scope of the new subscriber ID production order and/or raise the standard&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The bill attempts to fill a gap left in the wake of the &lt;a href=&#34;https://decisions.scc-csc.ca/scc-csc/scc-csc/en/item/14233/index.do&#34;&gt;&lt;em&gt;Spencer&lt;/em&gt;&lt;/a&gt; decision, which held that the police need authority in law to demand the subscriber ID attached to an IP from a telco like Shaw. The Court held that we have a high privacy interest in this information, given how readily this can connect us with our search history online.&lt;/p&gt;
&lt;p&gt;But it’s been unclear since &lt;em&gt;Spencer&lt;/em&gt; what a ‘reasonable law’ authorizing this demand would require. To obtain subscriber ID, police have been using the ‘general production order’ power on probable grounds (in section &lt;a href=&#34;https://laws-lois.justice.gc.ca/eng/acts/c-46/section-487.014.html&#34;&gt;487.014&lt;/a&gt; of the &lt;em&gt;Code&lt;/em&gt;). The bill creates a dedicated subscriber ID production order obtainable on reasonable suspicion. Will this stand, given how high the Court in &lt;em&gt;Spencer&lt;/em&gt; assessed the privacy interest at stake here to be? But wait, there’s more.&lt;/p&gt;
&lt;p&gt;The new power would work together with another important change. The bill adds a new section of the &lt;em&gt;Criminal Code&lt;/em&gt;, which states: “subscriber information means, in relation to any client of a person who provides services to the public… information related to the services provided to the subscriber or client, including (i) the types of services provided, [and] (ii) the period during which the services were provided”.&lt;/p&gt;
&lt;p&gt;In short, the new production order for subscriber ID would give police much of the same info about a person as with the “information demand” — except &lt;em&gt;where&lt;/em&gt; services were provided. It would engage an even higher privacy interest than what was contemplated in &lt;em&gt;Spencer&lt;/em&gt;. A warrant on reasonable suspicion is arguably not enough to constitute a reasonable law here It should be probable grounds.&lt;/p&gt;
&lt;p&gt;Parliament should amend the definition of “subscriber information” to narrow the ambit of what can be obtained. Limit it to simply: user name, pseudonym, address, telephone number and email address. Or, amend the order provision itself to require probable grounds — which would be redundant, since the current ‘general production order’ already does this. (But it does this for a good reason: see above.)&lt;/p&gt;
&lt;h3 id=&#34;3-dont-reduce-the-time-limit-for-challenging-a-production-order-so-drastically&#34;&gt;&lt;em&gt;3. Don’t reduce the time limit for challenging a production order so drastically&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The bill sets the periods for challenging new information demands and production orders for subscriber ID at 5 days. Within that time frame, you must comply or file a court challenge (a review). Currently, production orders give recipients 30 days. Many will find this challenging, thus watering down an important accountability mechanism that helps make these powers reasonable, especially where they allow police to obtain a warrant on reasonable suspicion rather than probable grounds.&lt;/p&gt;
&lt;p&gt;Time limits for challenging orders in new powers might be less than 30 days but more than 5. How about 14 days? And not from the time the order was made, but from the time order was received.&lt;/p&gt;
&lt;h3 id=&#34;4-rule-out-back-doors-to-encryption&#34;&gt;&lt;em&gt;4. Rule out back doors to encryption&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The bill’s new “Supporting Authorized Access to Information Act” (SAAIA) contains broad powers to compel electronic service providers to make technical modifications that give law enforcement direct access to private data. The bill states that no provider can be compelled to bring about “systemic vulnerabilities” in “electronic protections.” But it allows the Minister to define what constitutes a “systematic vulnerability,” as well as other key terms such as “encryption” or “authentication.”&lt;/p&gt;
&lt;p&gt;The bill should be amended to define these terms to rule out compelled decryption. Australia’s &lt;a href=&#34;https://www.legislation.gov.au/C2018A00148/latest/text&#34;&gt;Act&lt;/a&gt; defines them. We should adopt their definitions.&lt;/p&gt;
&lt;h3 id=&#34;5-subject-the-ministers-powers-under-the-act-to-independent-oversight&#34;&gt;&lt;em&gt;5. Subject the Minister’s powers under the Act to independent oversight&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Under the SAAIA, the Minister can order technical modifications — or make regulations about them — without having to first obtain an independent assessment of their necessity and proportionality. The Act also imposes sweeping secrecy requirements over ministerial measures, without the need to justify them before a court. And the Minister isn’t obliged to report to Parliament about how the powers are being used.&lt;/p&gt;
&lt;p&gt;One concern is that some measures could inadvertently result in real-time interceptions without a warrant. Another concern is that a telco might discover a weakness in relation to a given measure and not be able to share it with other telcos to avoid readily foreseeable harm to people’s privacy.&lt;/p&gt;
&lt;p&gt;The bill should be amended to set out factors the Minister must consider before imposing measures on any provider, such as their impact on privacy and cybersecurity. The Minister should have to obtain the Privacy Commissioner of Canada’s approval of any specific measures he or she seeks to impose. Confidentiality orders should require court approval. And the Minister should have to report annually to Parliament on the use of powers under the act.&lt;/p&gt;
&lt;h3 id=&#34;an-inclusive-process&#34;&gt;An inclusive process?&lt;/h3&gt;
&lt;p&gt;It’s good to see the government seeking input on C-2 from people outside the Department of Justice, the RCMP, and CSIS. It would be even better to see most of not all of these changes made when the bill returns early next year.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Do CSIS and Police Really Need More ‘Lawful Intercept’ Powers?</title>
      <link>https://www.robertdiab.ca/posts/lawful-intercept/</link>
      <pubDate>Sat, 25 Oct 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.robertdiab.ca/posts/lawful-intercept/</guid>
      <description>&lt;p&gt;Earlier this month, when no other party would support the Liberals in passing Bill C-2—the ‘Strong Borders Act,’ with its controversial surveillance powers—the government shelved it.&lt;/p&gt;
&lt;p&gt;More precisely, it split off the contentious parts of the bill from the customs and immigration provisions meant to appease our neighbours to the south and re-tabled those as &lt;a href=&#34;https://www.canada.ca/en/services/defence/securingborder/strengthen-border-security/understanding-stregthening-canada-immigration-system-borders-act.html&#34;&gt;Bill C-12&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But it didn’t withdraw C-2. The Minister of Public Safety &lt;a href=&#34;https://www.theglobeandmail.com/politics/article-strong-border-bill-c2-c12-anandasangaree-police-rcmp/&#34;&gt;insists&lt;/a&gt; that all of C-2 is still on the agenda.&lt;/p&gt;
&lt;p&gt;Among the most concerning parts of C-2 that were temporarily shelved are the ‘lawful access’ provisions found in a new statute that the Bill would have brought about: the ‘Supporting Authorized Access to Information Act.’&lt;/p&gt;
&lt;p&gt;As I’ve &lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5363319&#34;&gt;written earlier&lt;/a&gt;, this new law would have given the government the power to compel ‘electronic service providers’ like Shaw or Telus, or Apple and Google, to ‘install equipment’ or make technical modifications to give police and CSIS direct access to private data for real-time interception or seizure of stored communications. That’s your email, texts, and everything you have stored in iCloud, in case you were wondering.&lt;/p&gt;
&lt;p&gt;Of course, police or CSIS would still need a warrant or lawful authority (exigent circumstances, etc) before acting. The chief concern was that C-2 imposed few limits on what modifications the government could compel ESPs to make. It also shrouded the whole process of issuing orders and carrying out inspections to oversee them in an enormous degree of secrecy.&lt;/p&gt;
&lt;p&gt;The powers were ripe for abuse. Modifications could easily result in inadvertent police access or privacy breaches, without ever coming to light.&lt;/p&gt;
&lt;p&gt;More to the point, knowing that our communications and cloud infrastructure would have direct law enforcement access so deeply integrated would leave every Canadian feeling less secure about their privacy online.&lt;/p&gt;
&lt;p&gt;If you can never be sure whether the state might be listening, even inadvertently, you begin to assume it. Maybe most people do after Snowden. But with a lawful access regime like the one set out in C-2, the feeling would become all the more palpable, the concern less abstract.&lt;/p&gt;
&lt;h3 id=&#34;why-parliament-thinks-we-need-it&#34;&gt;Why Parliament thinks we need it&lt;/h3&gt;
&lt;p&gt;The National Security and Intelligence Committee of Parliamentarians has studied this issue for three years. In March, it produced a 78-page confidential report, which was lightly redacted before being &lt;a href=&#34;https://nsicop-cpsnr.ca/reports/rp-2025-09-15-sr/250915_NSICOP_Lawful_access_report.pdf&#34;&gt;made public&lt;/a&gt; last month. It offers a detailed defence of the need for a lawful access regime, but not one I find persuasive.&lt;/p&gt;
&lt;p&gt;However, the report is impressive in its scope. It contains an extensive overview of the privacy issues at stake, problems raised by compelling back doors to encryption, and the history of prior attempts in Canada to pass a lawful access bill. The Committee commissioned and drew upon papers from notable authorities including Ben Goold, Michael Geist, and Ron Deibert, making it a valuable resource.&lt;/p&gt;
&lt;p&gt;I briefly highlight here the crux of the committee’s findings. My aim is not to set out a detailed analysis, but to sketch the general argument.&lt;/p&gt;
&lt;p&gt;First, CSIS and the RCMP say they need to the power to compel folks at Telus and Shaw to install interception capabilities because they face serious “challenges” in accessing data even after obtaining warrants—though they can’t say how often or how serious those problems are:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Committee did not see any clear, empirical data to substantiate claims by Canada’s security and intelligence organizations that they face serious lawful access challenges because of rapidly evolving technology. CSIS and the RCMP do not systematically track how often they encounter various technological challenges in their national security investigations, for example, instances in which communications content could not be accessed because of encryption. As a result, they do not know in quantifiable terms the degree of impact and overall significance of these challenges.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Nevertheless, the Committee was satisfied that police and CSIS need more tools:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;However, the Committee heard compelling and detailed testimony about how the rapid pace of technological change has increased the complexity, operational risk and cost of national security investigations. More digital devices, more communications applications or apps, and more operating systems mean that investigators need to develop more methods of access, with an impact on both time and resources.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So how specific and compelling was this evidence?&lt;/p&gt;
&lt;p&gt;Earlier in the report, the “increasing complexity” refers to communication unfolding on a wider variety of apps and devices. Much of it is end-to-end encrypted. It’s often cross-border or served by platforms based in the US. To illustrate these trends, we’re given a few case studies involving national security investigations, but it isn’t clear how representative they are.&lt;/p&gt;
&lt;p&gt;The most concrete data we’re given pertains to the claim that the proliferation of apps and devices has increased the cost and complexity of investigations, including the use of On-Device Investigative Tools (ODITs). One chart shows that over the past seven years, successful deployments of ODITs—using special software to circumvent the encryption on a device like a phone—has declined over time. But the number of cases here is tiny: 2-3 each year from 2017 to 2020 and all uses of ODITs were successful; 15-16 in 2021-2022, with only half successful; then 8 in 2023, with only 2 successful; and none conducted in 2024. In short, over the years, police have struggled to break into a handful of phones.&lt;/p&gt;
&lt;p&gt;Another key argument was that often, by the time police or CSIS get a warrant to obtain data from Shaw or Telus, it’s deleted or it’s stored on servers in the US, making retrieval too slow and cumbersome. But again, the numbers are vague. There may be “investigative friction,” as &lt;a href=&#34;https://citizenlab.ca/2018/05/shining-light-on-encryption-debate-canadian-field-guide/&#34;&gt;one paper&lt;/a&gt; put it, but how much is unclear. We’re left with little more than a sentiment: police don’t like these impediments and would like them removed.&lt;/p&gt;
&lt;p&gt;The Committee’s conclusion — that “the RCMP and CSIS face significant challenges” and lawful access is the answer — is never clearly established. Nor is their other general argument for a lawful access bill: our other Five Eyes partners have one, and we should too.&lt;/p&gt;
&lt;h3 id=&#34;problems-with-this-picture&#34;&gt;Problems with this picture&lt;/h3&gt;
&lt;p&gt;But not all of our Five Eyes partners have the kind of lawful access regime the Committee is calling for, and not the kind set out in C-2. Only Australia and the UK compel providers to build intercept capabilities — and just because they do, doesn’t mean we should. As the report notes, the US and New Zealand instead set standards for data retention and access but not law compelling specific companies to install intercept capabilities.&lt;/p&gt;
&lt;p&gt;The Committee also sees a lawful access regime playing an important role in negotiations of mutual legal assistance treaties, like the one under way pursuant to the &lt;a href=&#34;https://en.wikipedia.org/wiki/CLOUD_Act&#34;&gt;US CLOUD Act&lt;/a&gt; or the 2nd Additional Protocol to the Budapest Convention on Cybercrime to which &lt;a href=&#34;https://www.justice.gc.ca/eng/cj-jp/cyber/id-di/index.html&#34;&gt;we are a signatory&lt;/a&gt;. Having a regime in place, the report argues, will help secure an agreement with the US allowing cross-border data access (from Google, Meta, Shaw) without requiring a court order in the target country.&lt;/p&gt;
&lt;p&gt;Now, of course, countries might agree to this in a treaty, but to ratify the treaty in domestic legislation, search powers would have to be Charter-compliant. But it’s easy to imagine some searches taking place beyond the ambit of the Charter.&lt;/p&gt;
&lt;p&gt;I’m not alone in positing a scenario where US police obtain data from a provider in Canada without going through Canada’s courts, and then seek the extradition of a Canadian to stand trial in the US. In this case, the person might argue a Charter breach &lt;a href=&#34;https://policyreview.info/articles/analysis/legal-geographies-extradition-and-sovereign-power&#34;&gt;when fighting extradition&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But this kind of impact of lawful access on data sharing agreements doesn’t feature in the report. The Committee touts lawful access without fully canvassing the ways that mutual assistance can compound the consequences of an unlawful search.&lt;/p&gt;
&lt;h3 id=&#34;some-silver-lining&#34;&gt;Some silver lining&lt;/h3&gt;
&lt;p&gt;But there are a few bright spots. The report affirms the merits of strong encryption and confirms that neither law enforcement nor government seek a power to compel back doors.&lt;/p&gt;
&lt;p&gt;It also recommends that a lawful access bill should define the intercept capabilities the government can impose on service providers and specify mandatory technical standards to be adopted.&lt;/p&gt;
&lt;p&gt;Put another way, the report envisions a more constrained set of powers around interception capabilities than the ones found in Bill C-2.&lt;/p&gt;
&lt;p&gt;Interestingly, there’s little in the report endorsing the sweeping secrecy provisions in C-2 that would conceal “technical modification” orders and their oversight.&lt;/p&gt;
&lt;p&gt;If the report was meant to justify C-2, the drafters of the bill seem to have gone well off script.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Will Canada’s new hate crime bill impact free speech online?</title>
      <link>https://www.robertdiab.ca/posts/bill-c9/</link>
      <pubDate>Fri, 26 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.robertdiab.ca/posts/bill-c9/</guid>
      <description>&lt;p&gt;Last week, the Liberal government tabled &lt;a href=&#34;https://www.parl.ca/DocumentViewer/en/45-1/bill/C-9/first-reading&#34;&gt;Bill C-9&lt;/a&gt;, containing three new criminal offences targeting hate speech — as a response to the alarming and appalling rise in antisemitic violence in Canada in the past two years, along with attacks against places of worship, schools, and community centres.&lt;/p&gt;
&lt;p&gt;The new offences primarily capture acts of intimidation of a physical sort: blocking access to a synagogue, mosque, or temple, or promoting hatred by waving flags or symbols of groups listed as terrorist entities.&lt;/p&gt;
&lt;p&gt;But two of the offences will apply to speech online and raise questions for me about where they fit in the panoply of hate speech offences in Canada — and whether we’re likely to see further regulation of online speech this fall.&lt;/p&gt;
&lt;p&gt;I thought I’d write this short post to help situate the new offences in the Criminal Code’s existing hate speech provisions, highlight what they add to what we already have, and remind readers about &lt;a href=&#34;https://www.parl.ca/DocumentViewer/en/43-2/bill/C-36/first-reading&#34;&gt;Bill C-36&lt;/a&gt; in 2021, which sought to revive a human rights law that would make hate speech a form of actionable discrimination — since it may be coming back.&lt;/p&gt;
&lt;h3 id=&#34;existing-hate-crimes-in-the-criminal-code-and-which-of-them-capture-online-speech&#34;&gt;Existing hate crimes in the Criminal Code (and which of them capture online speech)&lt;/h3&gt;
&lt;p&gt;Briefly, the Code criminalizes hate speech in the following ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the offence of &lt;strong&gt;“uttering threats”&lt;/strong&gt; (s. 264.1) to do violence, which, if motivated by racial animus, would be an aggravating circumstance at sentencing (s. 718.2(a)(i));&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;advocating or &lt;strong&gt;promoting genocide&lt;/strong&gt; of an identifiable group (s. 318);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;public incitement of hatred&lt;/strong&gt;: communicating a statement in any public place that incites hatred against any identifiable group where such incitement is likely to lead to a breach of the peace (s. 319(1));&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;wilful promotion of hatred&lt;/strong&gt;: communicating a statement, other than in private conversation, that wilfully promotes hatred against any identifiable group (s. 319(2);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;willful promotion of antisemitism&lt;/strong&gt;: communicating statements, other than in private conversation, that wilfully promote antisemitism by condoning, denying or downplaying the Holocaust (s. 319(2.1)-(3.1), with a number of exceptions and defences);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;under s. 83.2: committing any indictable &lt;strong&gt;offence for the benefit of a terrorist group&lt;/strong&gt; (which could include public incitement of hatred, s. 319(1)).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;advocating a terrorism offence in general&lt;/strong&gt; (s. 83.221): counseling another person to “commit a terrorism offence without identifying a specific terrorism offence”.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(also worth noting: warrant provisions for &lt;strong&gt;seizing terrorist propaganda&lt;/strong&gt; in s. 83.223 and &lt;strong&gt;hate propaganda&lt;/strong&gt; in s. 320)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Key provisions for targeting online speech are those in sections 319(1) and (2) — public incitement and wilful promotion of hatred. They capture speech online given the way the Code defines ‘public place’ and ‘statements’ in these provisions: “any place to which the public have access as of right or by invitation” and “words spoken or written or recorded electronically” (s. 319(7)).&lt;/p&gt;
&lt;p&gt;In at least three cases, courts have applied the promotion or incitement offence to speech online. But two of these were decisions about committal to trial (&lt;a href=&#34;https://canlii.ca/t/1vc0s&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://canlii.ca/t/fkmr5&#34;&gt;here&lt;/a&gt;), and the &lt;a href=&#34;https://canlii.ca/t/kfcx7&#34;&gt;third&lt;/a&gt; was a sentencing case.&lt;/p&gt;
&lt;p&gt;In 1990, the Supreme Court of Canada in &lt;a href=&#34;https://canlii.ca/t/1fsr1&#34;&gt;Keegstra&lt;/a&gt; held that section 319(2) — wilful promotion of hatred — infringed the freedom of expression in section 2(b) of the Charter because it targets speech content, but found it to be a reasonable limit on the right under section 1.&lt;/p&gt;
&lt;p&gt;The majority in Keegstra held the government’s aim of preventing the social harm of hate speech to be pressing and substantial. The offence minimally impaired expression for various reasons, including its being limited to ‘hatred,’ defined as the intense emotion of ‘vilification’ or ‘detestation’ rather than ‘disdain’ or ‘dislike.’ The dissent found the concept of hatred too vague and subjective, and the scope of the offence too broad given that it didn’t require statements likely to result in violence.&lt;/p&gt;
&lt;h3 id=&#34;what-bill-c-9-adds-to-the-picture&#34;&gt;What Bill C-9 adds to the picture&lt;/h3&gt;
&lt;p&gt;First, C-9 will codify the Keegstra definition of ‘hatred,’ as elaborated in the Supreme Court’s 2013 decision in &lt;a href=&#34;https://canlii.ca/t/fw8x4&#34;&gt;Whatcott&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Or does it?&lt;/p&gt;
&lt;p&gt;The Canadian Constitution Foundation &lt;a href=&#34;https://theccf.ca/liberal-hate-crimes-bill-raises-free-speech-concerns/&#34;&gt;says&lt;/a&gt; the definition in the bill “appears to lower the bar for hate speech set by the Supreme Court of Canada in cases like R v Keegstra and R v Whatcott, which could chill speech and public debate.”&lt;/p&gt;
&lt;p&gt;In Keegstra, Dickson CJC held: “the term ‘hatred’ [in 319(2)] connotes emotion of an intense and extreme nature that is clearly associated with vilification and detestation.”&lt;/p&gt;
&lt;p&gt;In Whatcott, Rothstein J, for the Court, held:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[w]here the term “hatred” is used in the context of a prohibition of expression in human rights legislation, it should be applied objectively to determine whether a reasonable person, aware of the context and circumstances, would view the expression as likely to expose a person or persons to detestation and vilification on the basis of a prohibited ground of discrimination.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But to be clear, the Supreme Court had already taken an objective approach to hatred in the criminal context in &lt;a href=&#34;https://canlii.ca/t/1jtfn&#34;&gt;Krymowski&lt;/a&gt; (2005). There it held that judges must “look at the totality of the evidence and draw appropriate inferences” to decide whether an accused person “intended to target” an identifiable group.&lt;/p&gt;
&lt;p&gt;C-9 will add to 319(7): “&lt;em&gt;&lt;strong&gt;hatred&lt;/strong&gt;&lt;/em&gt; means the emotion that involves detestation or vilification and that is stronger than disdain or dislike; (&lt;em&gt;haine&lt;/em&gt;)”&lt;/p&gt;
&lt;p&gt;It will also add in 319(6): “For greater certainty, the communication of a statement does not incite or promote hatred, for the purposes of this section, solely because it discredits, humiliates, hurts or offends.”&lt;/p&gt;
&lt;p&gt;I’m not convinced that C-9 lowers the bar for criminalizing hate speech by adding &lt;em&gt;these&lt;/em&gt; provisions.&lt;/p&gt;
&lt;h3 id=&#34;new-offences&#34;&gt;New offences&lt;/h3&gt;
&lt;p&gt;C-9 also adds three new offences. Cutting and pasting here from the DoJ’s &lt;a href=&#34;https://www.canada.ca/en/department-justice/news/2025/09/combatting-hate-act-proposed-legislation-to-protect-communities-against-hate.html&#34;&gt;press release&lt;/a&gt;, the bill will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Make it a crime to willfully intimidate and obstruct people from accessing places of worship, as well as schools, community centres and other places primarily used by an identifiable group.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make hate-motivated crime a specific offence, ensuring such conduct is more clearly denounced and that offenders are held accountable.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make it a crime to wilfully promote hatred against an identifiable group by displaying certain terrorism [i.e., listed entity] or hate symbols in public.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second and third offences will apply to speech online. I say this because the third offence (wilful promotion of hatred by displaying in public symbols of a terrorist group) will be slotted into 319, thus drawing on the definition of ‘public place’ noted above.&lt;/p&gt;
&lt;p&gt;The second offence here — committing any indictable offence when “motivated by hatred based on race, national or ethnic origin, language, colour, religion, sex, age, mental or physical disability, sexual orientation or gender identity or expression” — points to the new definition of hatred to be added to 319(7).&lt;/p&gt;
&lt;p&gt;But it will apply to speech online by virtue of the included offence possibly being 319(1) or (2). For example, if a white supremacist posts antisemitic or Islamophobic content on a blog or social media platform that meets the test for public incitement or wilful promotion under 319(1) or (2), they can be charged with this additional offence.&lt;/p&gt;
&lt;p&gt;Anaïs Bussières McNicoll of the Canadian Civil Liberties Association &lt;a href=&#34;https://ccla.org/press-release/ccla-bill-c-9-risks-criminalizing-peaceful-protest/&#34;&gt;believes&lt;/a&gt; the new hate-motivation offence may violate the presumption of innocence:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The new hate crime offence risks stigmatizing defendants throughout the entire judicial process, while they are still presumed innocent. The sentencing judge should continue to be responsible for labeling a defendant’s motivations and weighing their aggravating impact on sentencing, once a defendant has been found guilty of a criminal offence and all relevant evidence has been heard.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;is-the-new-displaying-hate-symbols-offence-redundant&#34;&gt;Is the new ‘displaying hate symbols’ offence redundant?&lt;/h3&gt;
&lt;p&gt;Richard Moon, Canada’s leading authority on the Charter right to free speech, in a &lt;a href=&#34;https://cfe.torontomu.ca/blog/2025/09/flying-flag-kneecap-and-bill-c-9&#34;&gt;post&lt;/a&gt; offering initial impressions of C-9, put his finger on a key issue about the wilful promotion by flag-waving offence: it doesn’t appear to capture anything new.&lt;/p&gt;
&lt;p&gt;As Moon writes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It is unclear what this provision adds to the existing ban [on wilful promotion of hatred] and indeed whether it will prohibit the public display of the Hezbollah or Hamas flags, which seems to be its purpose.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;The public display of a Nazi flag will ordinarily be viewed as communication that wilfuly promotes hatred, contrary to both the existing code provision and the new provision in Bill C-9. But… it is less clear that the display of the flags of Hezbollah, Hamas, or the Popular Front for the Liberation of Palestine can be seen, at least beyond a reasonable doubt, as “wilfully” promoting racial or religious hatred, since the formal mandate of these groups is anti-Zionist rather than antisemitic.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Put otherwise, waving a Nazi flag can only imply wilful promotion of hatred; waving the flag of a group whose meaning is ambiguous (terrorist org or, as some believe, the resistance) could only be wilful promotion if accompanied by other statements that tie the flag waving to hatred rather some other belief.&lt;/p&gt;
&lt;p&gt;Which is really just a way of saying: you can’t prove wilful promotion by flag waving unless you can prove it’s wilful promotion. And if you can do that, then you don’t need this new offence.&lt;/p&gt;
&lt;p&gt;I agree with Moon that this new offence may be “simply performative.”&lt;/p&gt;
&lt;p&gt;But then what did Justice Minister, Sean Fraser, mean when he said in the press conference introducing C-9 that these new provisions don’t ban wearing these symbols as you walk down the street — including Nazi insignia? (As the &lt;a href=&#34;https://www.theglobeandmail.com/politics/article-anti-hate-bill-sean-fraser-places-worship-religious-schools/&#34;&gt;Globe reports&lt;/a&gt;, Fraser said that whether it’s criminal would “depend upon the person’s behaviour and the circumstances.”)&lt;/p&gt;
&lt;p&gt;The bill contemplates a fine line between walking down the street with a Nazi t-shirt and standing on the steps of the Art Gallery in Vancouver (where large protests take place) and waving a big Nazi flag. In the one case, you are merely expressing a belief; in the other, you are wilfully promoting hatred because the &lt;em&gt;public display&lt;/em&gt; — i.e., flag waving, rather than merely wearing — entails &lt;em&gt;promotion&lt;/em&gt; of hated rather than mere expression.&lt;/p&gt;
&lt;p&gt;Again, I think we have this in 319(2) as it is. I don’t see how the new offence makes it easier for Crown to obtain a conviction for wilful promotion — with or without public display of a symbol — than it is now.&lt;/p&gt;
&lt;h3 id=&#34;the-possible-return-of-a-human-rights-law-on-hate-speech&#34;&gt;The possible return of a human rights law on hate speech?&lt;/h3&gt;
&lt;p&gt;Bill C-36, as you may recall, contained a version of the second offence here — making it a new offence to commit an indictable offence when motivated by hate — and combined it with the revival of a provision rescinded from the Canadian Human Rights Act in 2013 that allowed for a human rights complaint for hate speech.&lt;/p&gt;
&lt;p&gt;C-36 proposed to revive the old section 13 of the Act to make it a discriminatory practice to communicate “hate speech by means of the Internet… in a context in which the hate speech is likely to foment detestation or vilification of an individual or group of individuals on the basis of a prohibited ground of discrimination.”&lt;/p&gt;
&lt;p&gt;The bill codified the Supreme Court’s more limited definition of hatred in Whatcott, restricting the potential scope of a human rights action against hate speech.&lt;/p&gt;
&lt;p&gt;Briefly, in Whatcott the Court held that a provision in Saskatchewan’s human rights law banning hate speech violated s. 2(b) for being overbroad. The Court read in a more restricted definition of hatred — excluding the standard of “ridicules, belittles or otherwise affronts the dignity of” — and found the provision to be a reasonable limit under section 1.&lt;/p&gt;
&lt;p&gt;We may see the return of this provision this fall. I’ll save a discussion of its merits if and when a new bill is tabled — and whether reviving a human rights remedy would help curb the polarization and algorithmic amplification of hate speech that are upending so much of our politics these days.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Authorship After AI</title>
      <link>https://www.robertdiab.ca/posts/authorship-ai/</link>
      <pubDate>Fri, 19 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.robertdiab.ca/posts/authorship-ai/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://www.robertdiab.ca/images/Post-pic.jpg&#34; alt=&#34;image alt *&#34;&gt;&lt;/p&gt;
&lt;p&gt;A new article in AI Magazine draws an illuminating comparison between what AI is doing to writing and what photography did to art in the 1840s. It helps to make sense of a question many of us are thinking about more often: does increasing reliance on AI signal the end of writing?&lt;/p&gt;
&lt;p&gt;The insights in this piece resonate with me, given the quantum leap in my own use of AI over the past few months.&lt;/p&gt;
&lt;p&gt;I’m now making such frequent use of it — integrating it into my research, writing, and editing — that it has me wondering what’s really happening.&lt;/p&gt;
&lt;p&gt;As I describe in a &lt;a href=&#34;https://www.nationalmagazine.ca/en-ca/articles/law/opinion/2025/how-ai-has-made-me-more-productive&#34;&gt;piece&lt;/a&gt; for the CBA’s National Magazine, I’ve been dipping in and out of Claude, ChatGPT, and Perplexity constantly — to get a quicker lay of the land on new topics, reword sentences, and tighten drafts. But the pace and intensity feel like a transformation as momentous as the shift from typewriter to computer, or from paper-based research to the internet.&lt;/p&gt;
&lt;p&gt;To be clear, I’m not using AI to create texts. But using it more often to edit, it sometimes causes me to think about my claim to authorship. At what point does a suggestion — or re-write of a paragraph — mean it’s no longer me?&lt;/p&gt;
&lt;p&gt;In “&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/full/10.1002/aaai.70022&#34;&gt;Reclaiming authorship in the age of generative AI: From panic to possibility&lt;/a&gt;,” Mohsen Askari argues that we need to abandon the notion that “authorship is defined by the absence of tools” — that using AI contaminates the purity of writing.&lt;/p&gt;
&lt;p&gt;He sees AI as part of a continuum of tools from the pen to the typewriter to the reference manager. His central claim is provocative: “[w]hat matters is not whether help was involved, but whether the author stands behind the final work.”&lt;/p&gt;
&lt;h3 id=&#34;why-ai-is-like-early-photography&#34;&gt;Why AI is like early photography&lt;/h3&gt;
&lt;p&gt;The sharpest part of his piece is the analogy to photography in France in 1839. Painter Paul Delaroche famously declared: “From today, painting is dead!” The camera’s ability to mechanically capture the world posed an existential threat to painting not unlike our response to AI in writing: “shock, suspicion, and widespread declarations of the end of a creative tradition.”&lt;/p&gt;
&lt;p&gt;Early photography was dismissed as craftless. It seemed to require “no imagination, no hand, and no labour.” The prestige artists earned for mastery evaporated. Photography “democratized image-making.”&lt;/p&gt;
&lt;p&gt;But painting didn’t die. It ceased to be about reproduction and exploded with creativity through abstraction and experimentation. Meanwhile, photography itself became an art form: “Mastery emerged not from the act of clicking a shutter, but from timing, framing, lighting, and selection. In short: from judgment.”&lt;/p&gt;
&lt;p&gt;Askari sees the same happening with AI. Like photography, it produces results quickly and provokes fears of “fraudulence and depersonalization.” Yet using AI well involves more than typing a prompt; it requires “knowing what to ask, how to evaluate, when to refine, and when to reject.”&lt;/p&gt;
&lt;p&gt;AI can produce fluent text, he notes, but fluency is “not the same as quality, insight, or originality.” The real work lies in “asking the right questions, rephrasing, discarding early results, and returning with a clearer intent.”&lt;/p&gt;
&lt;p&gt;For Askari, writing with AI remains authorship when it involves real “sculpting”: “The user curates meaning. They filter the signal from the noise. Above all they remain accountable for what is kept and what is removed.”&lt;/p&gt;
&lt;h3 id=&#34;but-is-it-really-you&#34;&gt;But is it really you?&lt;/h3&gt;
&lt;p&gt;Askari may be stretching it too far. Surely authorship is more than “augmentation” or “curation.”&lt;/p&gt;
&lt;p&gt;But he has a point: authorship can be authentic even if not every sentence is one’s own. In conversation, we often grope toward an idea only for a friend to supply the better phrasing, which we readily adopt. They give us the words; we provided the idea. The proof is that our friend doesn’t just nod but lights up with an “aha.” This is the distinction Askari seems to be after.&lt;/p&gt;
&lt;p&gt;For people pressed with time, living with “interrupted attention spans,” or working in “linguistically diverse environments,” AI, he says, isn’t a “crutch or a cheat,” but a “tool that enables a different kind of flow.”&lt;/p&gt;
&lt;p&gt;In the academy, the flow he describes sparks anxiety because AI makes suddenly “easier, faster, and more accessible” skills that once took years to develop: “the ability to write well, think clearly, and publish independently.”&lt;/p&gt;
&lt;p&gt;We’re still aiming to cultivate these skills rather than handing them off to AI. How do we do this when AI offers to do it all for us?&lt;/p&gt;
&lt;h3 id=&#34;what-about-student-assignments&#34;&gt;What about student assignments?&lt;/h3&gt;
&lt;p&gt;When students hand in work with a strong trace of AI—a paper more polished than we suspect they would have written on their own—Askari urges us to question the reflexive view that AI use entails “the absence of thought.” He suggests we see the tool not as disrupting writing, but as having “supported” it.&lt;/p&gt;
&lt;p&gt;The question, he writes, is not “whether AI was used, but whether the author remained present, intentional, and accountable throughout the process.”&lt;/p&gt;
&lt;p&gt;This framing helps.&lt;/p&gt;
&lt;p&gt;When I recently used AI to revise the opening of a piece, I wondered whether it was still my writing if I adopted the suggestion. Askari’s point is that it’s yours not because you accept AI’s wording, but because what AI is rewording is your idea.&lt;/p&gt;
&lt;p&gt;If there’s a visible trace between your draft and AI’s output, then yes, you wrote it. AI only helped.&lt;/p&gt;
&lt;p&gt;But what about the term paper I received last spring in one of my courses that seemed written entirely by AI? Askari would say this wasn’t authorship any more than pointing a camera out a window and clicking would be art.&lt;/p&gt;
&lt;p&gt;It fails because the student had not “remained present, intentional, and accountable throughout the process.” They simply pointed and clicked. And that’s why it felt wrong.&lt;/p&gt;
&lt;p&gt;We might conclude that what matters is not whether AI polished a student’s prose, but whether we can still detect presence and intentionality. Original ideas, analogies, connections.&lt;/p&gt;
&lt;p&gt;The line will often be subtle. How much originality or intent is enough? How do we measure it? How do we teach students not to over-rely on AI?&lt;/p&gt;
&lt;p&gt;Not easy questions. But Askari’s insights remain useful.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>When AI Turns Deadly: Are Model Makers Responsible?</title>
      <link>https://www.robertdiab.ca/posts/ai-liability/</link>
      <pubDate>Sat, 30 Aug 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.robertdiab.ca/posts/ai-liability/</guid>
      <description>&lt;p&gt;This week, parents of Adam Raine, a California teen who committed suicide in April after a lengthy interaction with GPT-4o, &lt;a href=&#34;https://www.theguardian.com/technology/2025/aug/27/chatgpt-scrutiny-family-teen-killed-himself-sue-open-ai&#34;&gt;filed a lawsuit&lt;/a&gt; against OpenAI and its CEO, Sam Altman. The case follows a &lt;a href=&#34;https://www.nytimes.com/2024/10/23/technology/characterai-lawsuit-teen-suicide.html&#34;&gt;suit&lt;/a&gt; brought in late 2024 by the parents of a Florida teen, Sewell Setzer, who took his own life after engaging with a Character.AI chatbot impersonating Daenerys Targaryen from Game of Thrones.&lt;/p&gt;
&lt;p&gt;In early August, ChatGPT was also implicated in a &lt;a href=&#34;https://www.wsj.com/tech/ai/chatgpt-ai-stein-erik-soelberg-murder-suicide-6b67dbfb&#34;&gt;murder-suicide in Connecticut&lt;/a&gt; involving 56-year-old tech worker Stein-Erik Soelberg, who had a history of mental illness. Although the chatbot did not suggest that he murder his mother, it appears to have fueled Soelberg’s paranoid delusions, which led him to do so.&lt;/p&gt;
&lt;p&gt;OpenAI and other companies have been quick to respond with &lt;a href=&#34;https://openai.com/index/helping-people-when-they-need-it-most/&#34;&gt;blog posts&lt;/a&gt; and &lt;a href=&#34;https://openai.com/index/openai-anthropic-safety-evaluation/&#34;&gt;press releases&lt;/a&gt; outlining steps they are taking to mitigate risks from misuse of their models.&lt;/p&gt;
&lt;p&gt;This raises a larger question left unanswered in Canada after the &lt;a href=&#34;https://ised-isde.canada.ca/site/innovation-better-canada/en/artificial-intelligence-and-data-act&#34;&gt;Artificial Intelligence and Data Act&lt;/a&gt; died on the order paper in early 2025, when the last Parliament ended: what guardrails exist in Canadian law to govern the harmful uses of generative AI?&lt;/p&gt;
&lt;p&gt;Like the United States, Canada has no national or provincial legislation designed to impose liability on AI companies for harms caused by their products. The European Union passed an &lt;a href=&#34;https://artificialintelligenceact.eu/ai-act-explorer/&#34;&gt;AI Act&lt;/a&gt; in 2024 that does impose liability for harmful AI systems.&lt;/p&gt;
&lt;p&gt;But in both the EU law and the Canadian bill that was abandoned, there is a notable flaw in how liability is conceived.&lt;/p&gt;
&lt;p&gt;I explored this in &lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4680927&#34;&gt;a paper I wrote&lt;/a&gt; in late 2023, surveying early reports of harmful uses of language models (a suicide in Belgium, help with bomb-making, and other cases).&lt;/p&gt;
&lt;p&gt;My article garnered some interest on SSRN but only recently appeared in print (it was &lt;a href=&#34;https://commons.allard.ubc.ca/cgi/viewcontent.cgi?article=1372&amp;amp;context=ubclawreview&#34;&gt;published&lt;/a&gt; this month). The core argument was this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Both [the European and Canadian AI] bills are premised on the ability to quantify in advance and to a reasonable degree the nature and extent of the risk a system poses. This paper canvases evidence that raises doubt about whether providers or auditors have this ability. It argues that while providers can take measures to mitigate risk to some degree, remaining risks are substantial, but difficult to quantify, and may persist for the foreseeable future due to the intractable problem of novel methods of jailbreaking and limits to model interpretability.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The problem remains unresolved.&lt;/p&gt;
&lt;h3 id=&#34;the-only-guardrails-at-the-moment&#34;&gt;The only guardrails at the moment&lt;/h3&gt;
&lt;p&gt;The only mechanisms in Canada and the US for holding AI companies liable are laws on product liability, negligence, and wrongful death.&lt;/p&gt;
&lt;p&gt;Parents in both the California and Florida cases are suing the model makers (OpenAI and Character.AI, respectively) for wrongful death, a statutory cause of action that allows family members of the deceased to sue for damages including funeral expenses, mental anguish, loss of future financial support, and companionship. Plaintiffs must show the defendant’s negligence or intentional misconduct caused the death.&lt;/p&gt;
&lt;p&gt;Here, parents allege that chatbot makers were negligent in product design and failed to provide adequate warnings about risks.&lt;/p&gt;
&lt;p&gt;Canadian law works in a similar way. Provinces allow wrongful death suits for a wrongful act. Damage awards in Canada are much smaller than in the US and mostly limited to quantifiable losses. But plaintiffs can also claim that a model maker was negligent in offering a harmful product, or that it was defective or lacked adequate warnings.&lt;/p&gt;
&lt;p&gt;At the heart of negligence and product liability is the same question: what steps should OpenAI, Anthropic, or Google reasonably have taken to avoid harm?&lt;/p&gt;
&lt;p&gt;Put another way, in making chatbots available, companies clearly owe users a duty of care. The product carries risks, and harm to users is foreseeable.&lt;/p&gt;
&lt;p&gt;The key question, though, is: what is the standard of care?&lt;/p&gt;
&lt;p&gt;When can OpenAI and others be said to have done enough—or not enough—to avoid harm? If the standard is “reasonably safe” rather than “absolutely safe,” when is that threshold met? And can it even be met, given the nature of these systems?&lt;/p&gt;
&lt;p&gt;No one knows. But OpenAI and others are taking—and &lt;a href=&#34;https://openai.com/index/helping-people-when-they-need-it-most/&#34;&gt;publicizing&lt;/a&gt;—all the steps one might predict a tort lawyer would advise them to take.&lt;/p&gt;
&lt;p&gt;OpenAI admits its risk-detection mechanisms work better in shorter conversations and degrade as conversations lengthen. It is working to improve performance in longer chats.&lt;/p&gt;
&lt;p&gt;It is also improving detection across different types of harmful conversations, from suicidal to criminal. It has announced plans for parental controls to let parents monitor their child’s activity, and is rolling out systems to route some conversations to human overseers who can terminate the chat and lock the user out of further access.&lt;/p&gt;
&lt;p&gt;Whether these steps will be deemed sufficient—enough to absolve OpenAI and others of liability—remains to be seen.&lt;/p&gt;
&lt;p&gt;Much may depend on how a model was misused, what jailbreak was employed, and whether that misuse was foreseeable.&lt;/p&gt;
&lt;p&gt;In a broader sense, it is worth keeping perspective on AI risks. As tragic as these cases are, hundreds of millions of people use these tools daily, and many find them beneficial. But there are, inevitably, many ways to misuse them.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bill C-2 Backgrounder - the missing manual!</title>
      <link>https://www.robertdiab.ca/posts/c2backgrounder/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.robertdiab.ca/posts/c2backgrounder/</guid>
      <description>&lt;p&gt;Over a month later, the controversy over the &lt;a href=&#34;https://www.parl.ca/DocumentViewer/en/45-1/bill/C-2/first-reading&#34;&gt;Strong Borders Act&lt;/a&gt; continues.&lt;/p&gt;
&lt;p&gt;Privacy experts are still sounding the alarm over the astonishing breadth of some of the new powers — allowing police to demand from a doctor, lawyer, anyone who “provides a service” information about a person’s account without a warrant; a power to compel Shaw or Google to “install equipment” that would give police or CSIS access to personal data — the list goes on.&lt;/p&gt;
&lt;p&gt;Following my last &lt;a href=&#34;https://www.robertdiab.ca/posts/strong-borders-search/&#34;&gt;post&lt;/a&gt; that looked in some detail at parts of the bill, the government has issued a &lt;a href=&#34;https://www.justice.gc.ca/eng/csj-sjc/pl/charter-charte/c2_2.html&#34;&gt;Charter statement&lt;/a&gt; that drew &lt;a href=&#34;https://www.youtube.com/watch?v=t6yjuEOjMPo&#34;&gt;criticism&lt;/a&gt; for being self-serving, even misleading. Along with others, I wrote &lt;a href=&#34;https://www.techpolicy.press/buried-in-a-border-bill-canada-creates-major-new-search-powers-over-private-data/&#34;&gt;opinion&lt;/a&gt; &lt;a href=&#34;https://www.cigionline.org/articles/canadas-lawful-access-bill-heavy-on-secrecy-light-on-accountability/&#34;&gt;pieces&lt;/a&gt; and spoke about the bill on &lt;a href=&#34;https://www.michaelgeist.ca/2025/06/law-bytes-podcast-episode-236/&#34;&gt;Law Bytes&lt;/a&gt; and other venues.&lt;/p&gt;
&lt;p&gt;But I noticed there was still some confusion and uncertainty about many aspects of the bill. Rather than wait for a Parliamentary backgrounder to appear, I decided to put together my own overview of all aspects of the bill touching on privacy — and to offer an independent assessment of them in relation to section 8 of the Charter (guaranteeing “a right to be secure against unreasonable search or seizure”).&lt;/p&gt;
&lt;p&gt;The result is a paper I’ve posted to SSRN titled “&lt;a href=&#34;https://papers.ssrn.com/abstract=5363319&#34;&gt;Bill C-2 Backgrounder: New Search Powers in the Strong Borders Act and Their Charter Compliance&lt;/a&gt;”.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve tried to provide more context than is found in the government’s Charter statement, by detailing how new powers expand on or amend those currently in force.&lt;/p&gt;
&lt;p&gt;The paper looks at more controversial parts of the bill, including the whole new lawful access act contained in C-2, and declaratory provisions in the Criminal Code asserting that police don’t need a warrant for subscriber ID or an ‘information demand’ with voluntary compliance — and an indemnity for those who comply.&lt;/p&gt;
&lt;p&gt;I plan to keep the paper up to date (on &lt;a href=&#34;https://papers.ssrn.com/abstract=5363319&#34;&gt;SSRN&lt;/a&gt;) as the bill moves through second and third reading — and to post those updates here. Comments are welcome!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Major new search powers in the Strong Borders Act: are they constitutional?</title>
      <link>https://www.robertdiab.ca/posts/strong-borders-search/</link>
      <pubDate>Sun, 08 Jun 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.robertdiab.ca/posts/strong-borders-search/</guid>
      <description>&lt;p&gt;The Liberal’s first bill in Parliament last week proposes a raft of new search powers to give police easier access to our private data. They may turn out to be the most consequential search powers added to the Criminal Code in the past decade.&lt;/p&gt;
&lt;p&gt;They have little to do with the primary aim of the bill, strengthening borders by expanding powers in customs and immigration.&lt;/p&gt;
&lt;p&gt;Tucked in the middle of &lt;a href=&#34;https://www.parl.ca/LegisInfo/en/bill/45-1/C-2&#34;&gt;Bill C-2&lt;/a&gt; are measures that revive long-standing aims to pass “lawful access” legislation that will make it easier for police to obtain subscriber information attached to an ISP account (with Shaw or Telus) and give police direct access to private data held by ISPs or platforms like iCloud, Gmail, or Instagram.&lt;/p&gt;
&lt;p&gt;I’ve written a general overview of these powers for The Conversation &lt;a href=&#34;https://theconversation.com/the-proposed-strong-borders-act-gives-police-new-invasive-search-powers-that-may-breach-charter-rights-258257&#34;&gt;here&lt;/a&gt;, and Michael Geist has a very &lt;a href=&#34;https://www.theglobeandmail.com/opinion/article-strong-borders-act-privacy-threats-security/&#34;&gt;informative op-ed&lt;/a&gt; in the Globe that sets out a wider context and walks through some of the provisions in detail. If you’re new to this story, you might begin there.&lt;/p&gt;
&lt;p&gt;In this post, I offer a few thoughts on the constitutionality of three key powers in the bill: the new production order for subscriber info; the new information demand power; and the provisions that compel service providers to assist police in gaining direct access to personal data.&lt;/p&gt;
&lt;p&gt;This is a long post, almost 3k words. It might have been three shorter ones, but I thought I’d put it all in one post.&lt;/p&gt;
&lt;p&gt;It’s meant for those looking for a deeper dive on the constitutional questions.&lt;/p&gt;
&lt;h3 id=&#34;what-do-you-mean-by-constitutional&#34;&gt;What do you mean by ‘constitutional’?&lt;/h3&gt;
&lt;p&gt;The larger issue here is whether these provisions will survive a challenge under section 8 of the Charter of Rights and Freedoms, guaranteeing “everyone has the right to be secure against unreasonable search or seizure.”&lt;/p&gt;
&lt;p&gt;Two things to keep in mind about section 8: What is a search? And when will a search be reasonable? &lt;/p&gt;
&lt;p&gt;A search for the purpose of section 8 is anything done by a state agent for an investigative purpose that interferes with a reasonable expectation of privacy in a place or thing (&lt;a href=&#34;https://canlii.ca/t/k358f&#34;&gt;R v Bykovets&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;A search will be reasonable where it is authorized by law, the law is reasonable, and it is carried out in a reasonable manner (&lt;a href=&#34;https://canlii.ca/t/1ftnd&#34;&gt;R v Collins&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The powers created in this new bill set out authority for a search. The issue here is whether each of them sets out a ‘reasonable law’ authorizing a search.&lt;/p&gt;
&lt;p&gt;(In case you’re interested, I’ve co-authored an entire book on section 8, which you can check out &lt;a href=&#34;https://www.robertdiab.ca/books/search.html&#34;&gt;here&lt;/a&gt;.)&lt;/p&gt;
&lt;h3 id=&#34;relevant-background-production-orders-and-the-spencer-situation&#34;&gt;Relevant background: production orders and the Spencer situation&lt;/h3&gt;
&lt;p&gt;In 2004, Parliament &lt;a href=&#34;https://www.canlii.org/en/ca/laws/astat/sc-2004-c-3/latest/sc-2004-c-3.html&#34;&gt;created&lt;/a&gt; what are called ‘production orders’ to give police the power to ask an internet or cellphone service provider to hand over data about digital communications, including the content of messages.&lt;/p&gt;
&lt;p&gt;That power required reasonable suspicion, and it was challenged under section 8 of the Charter as being too low a standard, giving rise to an unreasonable search.&lt;/p&gt;
&lt;p&gt;In 2014, the BC Supreme Court &lt;a href=&#34;https://canlii.ca/t/gtr5r&#34;&gt;said&lt;/a&gt; it was too low: it should be probable grounds; the Alberta Court of Appeal &lt;a href=&#34;https://canlii.ca/t/gdqg3&#34;&gt;disagreed&lt;/a&gt;: it should only be reasonable suspicion.&lt;/p&gt;
&lt;p&gt;That same year Parliament passed &lt;a href=&#34;https://www.parl.ca/LegisInfo/en/bill/41-2/C-13&#34;&gt;Bill C-14&lt;/a&gt;, which created a general production order requiring probable grounds (487.014) and four more specific production orders requiring only reasonable suspicion — for tracing communications (e.g., metadata attached to email or phone calls), transmission data (call or text histories); tracking data (location data); and financial data (487.015 to 487.018).&lt;/p&gt;
&lt;p&gt;Meanwhile, in June of 2014, Supreme Court of Canada decided &lt;a href=&#34;https://canlii.ca/t/g7dzn&#34;&gt;R v Spencer&lt;/a&gt;, which held that subscriber information attached to an IP address — the name and physical address of the person linked to it — is private, because it associates a person with their online search history. Police can’t demand it from an ISP without authority in law to do so (which may or may not involve a warrant).&lt;/p&gt;
&lt;p&gt;The Court in Spencer noted (at para 11) that police had demanded the subscriber ID from Shaw without first obtaining a production order in that case — thus contemplating its use as a means for doing so.&lt;/p&gt;
&lt;p&gt;But the Court did not address the question of what kind of search power would be reasonable to obtain subscriber info. After explaining why provisions in private sector legislation (PIPEDA) didn’t authorize the search, the Court simply concluded (in para 73) that “in the absence of exigent circumstances or a reasonable law,” police couldn’t lawfully search (i.e., demand) it.&lt;/p&gt;
&lt;p&gt;So what remained unclear after Spencer was: what is a reasonable search law that authorizes police to make a demand for subscriber information?&lt;/p&gt;
&lt;p&gt;The presumptive standard for a reasonable search in criminal law (i.e., what constitutes a “reasonable law” authorizing a search) is one involving a warrant issued on “reasonable grounds to believe” (probable grounds) that an offence has been or will be committed, rather than “reasonable suspicion.” It would seem, then, that a demand for subscriber ID should be a warrant on probable grounds.&lt;/p&gt;
&lt;p&gt;Things said in Spencer support this inference. It held the privacy interest in subscriber information is high, given that it links a person to search activity that can be highly revealing. Anything less than probable grounds would not strike the right balance between law enforcement interests and personal privacy. But at least one privacy scholar &lt;a href=&#34;https://digitalcommons.osgoode.yorku.ca/cgi/viewcontent.cgi?article=1298&amp;amp;context=sclr&#34;&gt;disagrees&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the wake of Spencer, to obtain subscriber info, police have been using the new general production order power added in 2014, requiring probable grounds. Again, this isn’t a powered tailored specifically for obtaining subscriber ID, so it’s unclear whether anything less would suffice. Police and Crown hope so. Probable grounds is a relatively high standard; why not just a warrant on reasonable suspicion?&lt;/p&gt;
&lt;h3 id=&#34;privacy-in-a-set-of-numbers-alone&#34;&gt;Privacy in a set of numbers alone?&lt;/h3&gt;
&lt;p&gt;And what about demanding an IP address? Sometimes police can’t get far without asking an ISP or an online platform like Instagram to reveal a user’s IP address. Did they need a warrant for this? Was an IP address on its own private?&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;https://canlii.ca/t/k358f&#34;&gt;R v Bykovets&lt;/a&gt;, the Supreme Court of Canada held that an IP address is private because it readily links a person to their online activity. But the Court didn’t specify what kind of power would render a search (demand) for an IP address reasonable.&lt;/p&gt;
&lt;p&gt;At para 85 of the decision, Karakatsanis J for the majority, points the production order power in section 487.015(1) of the Code (for transmission data) on reasonable suspicion as possible tool police might use here. This is obiter, since the Court is not being asked whether the use of this to demand an IP address would constitute a reasonable law. Yet we can assume that the judges in the majority think that a warrant on reasonable suspicion would suffice.&lt;/p&gt;
&lt;h3 id=&#34;new-production-order-in-the-strong-borders-act&#34;&gt;New production order in the Strong Borders Act&lt;/h3&gt;
&lt;p&gt;The new bill gives police and Crown what they want: a production order power tailored to making a demand for subscriber info by obtaining a warrant issued on reasonable suspicion that a federal offence has been or will be committed (a new 487.0181(2) of the Criminal Code).&lt;/p&gt;
&lt;p&gt;Will this be constitutional? More specifically, a search conducted under this power will be authorized by law, but is this law reasonable?&lt;/p&gt;
&lt;p&gt;There is no single test for when a law authorizing a search is reasonable under section 8 of the Charter. But the Supreme Court has generally considered four factors: whether the power relates to a criminal or regulatory offence; the state or law enforcement interest at issue; the impact on personal privacy; and the oversight and accountability safeguards.&lt;/p&gt;
&lt;p&gt;Demanding subscriber info on reasonable suspicion is, I think, likely to be found unreasonable. In this case, the privacy interest is high (i.e., the online activity linked to a person’s name). Given things said about this in Spencer, this alone could favour a finding that nothing less than probable grounds is reasonable.&lt;/p&gt;
&lt;p&gt;Further possible support may be found in &lt;a href=&#34;https://canlii.ca/t/fqxmc&#34;&gt;R v Tse&lt;/a&gt;, which held that emergency wiretap provisions of the Code were unreasonable for failing to include a post facto notice requirement to persons affected. In this case, there’s no requirement to advise a person that they were subject to a production order, if charges do not follow. Not sure a court would view production order powers to be sufficiently analogous to wiretap provisions. But I flag it as a potential consideration.&lt;/p&gt;
&lt;h3 id=&#34;the-new-information-demand-power&#34;&gt;The new “information demand” power&lt;/h3&gt;
&lt;p&gt;Bill C-2 also creates a new power on the part of police to demand information. In some cases, police may only ask if a service provider has info about something. In other cases, they can demand the info itself.&lt;/p&gt;
&lt;p&gt;Under a new section 487.0121 in the Code, police can ask a service provider whether they have “provided services to any subscriber or client, or to any account or identifier.” If so, police can demand to be told where and when service was provided — along with info about any other providers who may have offered the person service.&lt;/p&gt;
&lt;p&gt;They can do this on reasonable suspicion alone, without a warrant.&lt;/p&gt;
&lt;p&gt;Police can thus ask Shaw or Gmail things like: does this user have an account with you? Do you have an IP address or phone number associated with their account? If so, tell us where and when you provided it.&lt;/p&gt;
&lt;p&gt;Why do police need this power? Aren’t police free to ask questions as part of their investigation? Is there not a distinction between a person describing to police what they know or have observed and police demanding to see it themselves? Can’t we assume that police only carry out a search when they ask for and receive private data itself?&lt;/p&gt;
&lt;p&gt;Recall that a search is anything done for an investigative purpose that interferes with a reasonable expectation of privacy. Police demanding private information in the hands of a third party can constitute a search. For example, police carried out a search in Spencer by asking Shaw: whose name is attached to this IP address?&lt;/p&gt;
&lt;p&gt;What is contemplated here differs in some ways but is similar in others. Police might ask simply: do you have a name (or an account) attaching to this IP address? Did you lease this IP address to a person? Or they might ask: when and where did you provide use of this IP address?&lt;/p&gt;
&lt;p&gt;In some cases, depending on the question and the limited info revealed by the answer, it may not amount to a search. But in some cases it can. &lt;/p&gt;
&lt;p&gt;If police have a name, or an IP or email address and they ask a dating, gambling, or porn website whether they have a user account related to any of them, a “yes” in response could be quite revealing. If a service provider can link a person to a location, or more than one, in a window of time, this could also be invasive.&lt;/p&gt;
&lt;p&gt;Should this too require a warrant? We’re in genuinely new terrain here.&lt;/p&gt;
&lt;p&gt;The information demand power gives police authority to go poking around the edges of our digital lives — knocking on the doors of anywhere we’ve left a digital trace — to ask questions that could readily create a clear picture of who we are and where we’ve been. All on nothing more than reasonable suspicion.&lt;/p&gt;
&lt;p&gt;I can see a challenge to this power leading to a deeply divided the Supreme Court decision similar to that in &lt;a href=&#34;https://canlii.ca/t/k358f&#34;&gt;Bykovets&lt;/a&gt;, where half the Court says: reasonable suspicion is enough, and the other half says no, it should require a warrant.&lt;/p&gt;
&lt;p&gt;I suspect it will come down to half the Court seeing this power as too preliminary to pose a real threat to privacy and police needing some leeway to act without undue hindrance, and half the Court seeing this as too close in nature to a means of circumventing the protections around subscriber ID and IP addresses. In some cases a positive answer to the question: “does this user have an account with you?” will be all the police need to know to link a person with an extensive amount of personal data.&lt;/p&gt;
&lt;p&gt;If I were a betting man, which I’m not, I would bet that a majority of the Court will find this power reasonable. (But there will be a wonderful, eloquent dissent, probably by Karakatsanis J or Martin J or maybe both, on the importance of privacy and the need for a warrant.)&lt;/p&gt;
&lt;p&gt;Briefly, Bill C-2 also extends to agents of the Canadian Security Intelligence Service the ability to make an information demand on no grounds at all. But they may not target a Canadian citizen or permanent resident. Given the high state interest in these cases and the limited privacy interest engaged, this power is likely to be found reasonable.&lt;/p&gt;
&lt;h3 id=&#34;the-lawful-access-provisions&#34;&gt;The lawful access provisions&lt;/h3&gt;
&lt;p&gt;Bill C-2 contains a whole new statute called the “Supporting Authorized Access to Information Act,” which brings about a “lawful access” regime for private data that police and Crown have long been seeking.&lt;/p&gt;
&lt;p&gt;(See Professor Geist’s &lt;a href=&#34;https://www.theglobeandmail.com/opinion/article-strong-borders-act-privacy-threats-security/&#34;&gt;Globe article&lt;/a&gt; on the history of this.)&lt;/p&gt;
&lt;p&gt;The Criminal Code has long had something called an assistance order, which compels third parties to assist police in executing a warrant. (Open that storage locker please.) The lawful access provisions do the same but on a larger scale.&lt;/p&gt;
&lt;p&gt;They impose of obligations on “electronic service providers,” or anyone providing a digital service (storage, creation, or transmission of data) to people in Canada or if situated here, and more onerous obligations on a class called “core providers” who can be added to a schedule to the Act.&lt;/p&gt;
&lt;p&gt;An ESP can be ordered to “provide all reasonable assistance, in any prescribed time and manner, to permit the assessment or testing of any device, equipment or other thing that may enable an authorized person to access information”.&lt;/p&gt;
&lt;p&gt;But core providers will be subject to regulations that mandate the “installation… of any device, equipment or other thing that may enable an authorized person to access information”.&lt;/p&gt;
&lt;p&gt;A core provider might be Google or Meta, Shaw or Telus. And the equipment at issue could enable direct access to accounts, stored files, data logs, and so on.&lt;/p&gt;
&lt;p&gt;There are two important limits on this.&lt;/p&gt;
&lt;p&gt;One is that police (or an authorized person, such as a CSIS agent) can only go ahead and access data or demand it if they have authority to do so under law — which may or may not involve a warrant, reasonable grounds, and so on.&lt;/p&gt;
&lt;p&gt;The other limit applies to both ESPs and core providers: they do not have to follow an order “if compliance… would require the provider to introduce a systemic vulnerability in electronic protections related”. I take this to mean that they cannot be compelled to install a backdoor to encryption.&lt;/p&gt;
&lt;p&gt;Are these powers immune to challenge under section 8 of the Charter?&lt;/p&gt;
&lt;p&gt;They do not contemplate a search directly. But depending on how an assistance order is used, it could result in an unreasonable search.&lt;/p&gt;
&lt;p&gt;For example, a while ago, there was a &lt;a href=&#34;https://www.robertdiab.ca/papers/Password.pdf&#34;&gt;debate&lt;/a&gt; about whether using an assistance order to compel a person to provide police their password might amount to an unreasonable search.&lt;/p&gt;
&lt;p&gt;The companies subject to a requirement under this new lawful access statute could challenge it in court — either in response to an order made to them specifically or under a regulation that applies to them as a core provider (on administrative law principles).&lt;/p&gt;
&lt;p&gt;But it’s harder to imagine a case where police have conducted a search on lawful grounds, or with a valid warrant, which is found to be unreasonable under section 8 because police were able to gain access to private data more readily through technical means of access made possible under this new statute.&lt;/p&gt;
&lt;p&gt;But I can envision two possible exceptions.&lt;/p&gt;
&lt;p&gt;One is if the means of access mandated under the new Act amounts to an interception: realtime access to data that police use to obtain the data at issue. An accused person would need to show, however, that police came into possession of their private data in realtime and without a warrant under the wiretap (interception) provisions in Part VI of the Criminal Code. (See the &lt;a href=&#34;https://canlii.ca/t/fwq20&#34;&gt;Telus&lt;/a&gt; case for more on this distinction.)&lt;/p&gt;
&lt;p&gt;Another exception is simply that police gained quick access technically, but without a lawful basis (a warrant, etc.).&lt;/p&gt;
&lt;p&gt;But it isn’t inconceivable that the Supreme Court might eventually say that mandating certain measures, means, or forms of access amount to an unreasonable search even if used with lawful authority such as a warrant. These might include means that somehow give police with a warrant access to data being created now and in the future, in addition to data already created.&lt;/p&gt;
&lt;p&gt;If you’re still with me, thanks for reading! I’ll continue to follow the bill as it makes its way through Parliament and try to post about it here.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Testing the waters with Deep Research</title>
      <link>https://www.robertdiab.ca/posts/deepresearch/</link>
      <pubDate>Tue, 04 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.robertdiab.ca/posts/deepresearch/</guid>
      <description>&lt;p&gt;Last month OpenAI unveiled a new tool for producing lengthy reports with citations to sources on the web. It uses one of the company’s best ‘chain of reasoning’ models to deliver output that far exceeds the quality of what similar tools from Google and Perplexity AI can do – tools that are also called ‘Deep Research,’ as it happens.&lt;/p&gt;
&lt;p&gt;But initially, OpenAi’s version was only available to folks with the $200 US a month “pro” subscription. We had to take on faith effusive reviews, like this one from &lt;a href=&#34;https://www.reddit.com/r/ChatGPTPro/comments/1iis4wy/deep_research_is_hands_down_the_best_research/?rdt=52148&#34;&gt;Reddit&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Deep Research has completely changed how I approach research. I canceled my Perplexity Pro plan because this does everything I need. It’s fast, reliable, and actually helps cut through the noise.&lt;/p&gt;
&lt;p&gt;For example, if you’re someone like me who constantly has a million thoughts running in the back of your mind—Is this a good research paper? How reliable is this? Is this the best model to use? Is there a better prompting technique? Has anyone else explored this idea?—this tool solves that.&lt;/p&gt;
&lt;p&gt;It took a 24-minute reasoning process, gathered 38 sources (mostly from arXiv), and delivered a 25-page research analysis. It’s insane.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Not everyone was so enthused. One commentator &lt;a href=&#34;https://theconversation.com/openais-new-deep-research-agent-is-still-just-a-fallible-tool-not-a-human-level-expert-249496&#34;&gt;noted&lt;/a&gt; that it can “miss key details, struggle with recent information and sometimes invents facts.”&lt;/p&gt;
&lt;p&gt;The Verge had a &lt;a href=&#34;https://www.theverge.com/openai/607587/chatgpt-deep-research-hands-on-section-230&#34;&gt;piece&lt;/a&gt; about using Deep Research to produce a report on the judicial treatment of section 230 of the Communications Decency Act in the last five years – concluding that “it got the facts right but the story wrong.” Although none of the cases it cited were made-up, and its summary was generally accurate, it had one major problem: it ended in 2023. But 2024 was “a rollicking year for Section 230,” with many important developments, as a law scholar quoted in the article pointed out.&lt;/p&gt;
&lt;p&gt;When I first read about OpenAI’s new tool, I was keen to find out whether it could look up sources on third-party databases like &lt;a href=&#34;https://www.canlii.org/en/&#34;&gt;Canlii&lt;/a&gt; or &lt;a href=&#34;https://www.jstor.org/&#34;&gt;JSTOR&lt;/a&gt;. If it could do this, DP would be quite powerful. You could ask it to find a case about X and it would formulate the query, run the search and – most importantly – read through the cases to find the needle in the haystack.&lt;/p&gt;
&lt;p&gt;For the moment, however, it doesn’t do this. But OpenAI &lt;a href=&#34;https://openai.com/index/introducing-deep-research/&#34;&gt;says&lt;/a&gt; that accessing databases like Canlii is on its way.&lt;/p&gt;
&lt;p&gt;(Incidentally, I’ve been writing about how much better free or almost free AI has become at doing brief overviews of Canadian law. I’ve got a piece on the way documenting how well OpenAI’s reasoning model GPT o1 produced a summary on the law of unjust enrichment in 500 words, which I knew little about. It came up with a cogent summary, with correct citations to the three leading Supreme Court of Canada decisions on point and the main 3-part test to be applied. Check it out &lt;a href=&#34;https://chatgpt.com/share/67b5f8be-e58c-8003-8db1-486086423bb5&#34;&gt;here&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;The thrust of this post, however, is to report on my own test drive with OpenAI’s Deep Research. As a GPT Plus subscriber (30$ Canadian a month), I gained access to DR only last week but couldn’t think of a good query to test it with. With “plus” users getting only 10 queries a month, I’m inclined to be sparing with them.&lt;/p&gt;
&lt;p&gt;Here was my ungrammatical query:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What uses are being made in Canada to use artificial intelligence in decision-making by government agencies or entities, and what policy statements or guidelines have been issued by government or agencies with respect to this?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As you may know, before it embarks on a search that can last between about 5 and 30 minutes, it asks you a few questions to sharpen the boundaries. It asked me:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Are you looking for information on AI use by government agencies across all levels (federal, provincial, municipal), or just at the federal level? Also, would you like details on specific areas of application (e.g., public safety, healthcare, immigration, etc.)? Lastly, are you interested in ethical considerations and public consultations regarding AI in government decision-making?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I told it to be as inclusive as possible.&lt;/p&gt;
&lt;p&gt;What it produced was thoroughly impressive. It took 7 minutes and came back with an 11,000 word document titled “AI in Government Decision-Making in Canada” that cited 27 sources. You can read it &lt;a href=&#34;https://chatgpt.com/share/67c5a7b0-6320-8003-bcb2-52e3bb0e7167&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It was both informative and sufficiently engaging that I read it all the way through, and I learned an enormous amount. (I then got it to do a 1,000 word summary, which you can find at the end of the thread.)&lt;/p&gt;
&lt;p&gt;The report was impressive both in terms of what it covered and where it pointed. It touched on the use of AI at federal, provincial, and municipal levels across Canada and in various fields: policing, healthcare, immigration, social services, transportation, even the courts.&lt;/p&gt;
&lt;p&gt;It also struck a nice balance between useful and reliable government policy docs and reports, and shorter news items.&lt;/p&gt;
&lt;p&gt;What struck me reading it was that it would take me easily a week of surfing, reading, note-taking, and compiling to produce something this good. Maybe more.&lt;/p&gt;
&lt;p&gt;It would no doubt have been a better report. More selective in some ways, more discerning, maybe more probing.&lt;/p&gt;
&lt;p&gt;But this was about 70 to 80% as good as I could do myself – &lt;em&gt;in 7 minutes&lt;/em&gt;. It hit all the bases, all the major stories in the government use of AI in recent years: Clearview AI, Chinook, interventions by the Federal Privacy Commissioner, major policy statements on the use of AI.&lt;/p&gt;
&lt;p&gt;Quibble with this as you might, but this is not a minor development. The sources are real. The general summary is cogent and more or less accurate as far as it goes. Is it missing that great paper by so-and-so on this or that aspect of the problem? No doubt. Does it contain every relevant story, all the relevant policies, cases, and so on. No it doesn’t.&lt;/p&gt;
&lt;p&gt;But is it worth consulting &lt;em&gt;as a starting point&lt;/em&gt;? Do I know much more about this topic than I did before I ran the query? Absolutely.&lt;/p&gt;
&lt;p&gt;I come away from Deep Research feeling more optimistic about the utility of AI in research, and legal research in particular. I can see a point in time on the horizon when AI will produce a better first draft of an outline of argument or opinion than we could possibly do in less than a few days, even with a good grounding in the field.&lt;/p&gt;
&lt;p&gt;It’s even to the point of making me question my assumptions about AI not being a substitute for really knowing the law – that people without a solid foundation in law won’t know how to prompt effectively. Just not sure about this any more.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Are sexual deepfakes not a crime in Canada?</title>
      <link>https://www.robertdiab.ca/posts/deepfakes/</link>
      <pubDate>Sat, 11 Jan 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.robertdiab.ca/posts/deepfakes/</guid>
      <description>&lt;p&gt;In late December, the Toronto Star ran a &lt;a href=&#34;https://www.pressreader.com/canada/toronto-star/20241228/281505051838722?srsltid=AfmBOoolvfiFtv7JyM8BUq6BehhsJJvu_Kh90fqJ33KCmzEzsivPi5Zq&#34;&gt;story&lt;/a&gt; about a boy in high school who had created a series of pornographic deepfakes of other girls at his school using images of their faces on Instagram. The nude pictures were discovered on his phone inadvertently, during sleepover when a friend went looking for a selfie taken on his device. Once discovered, the girls were alerted (with screenshots) and soon police were at his door.&lt;/p&gt;
&lt;p&gt;They grappled with whether creating the images was criminal. After questioning other boys believed to have seen the images and consulting with Crown, police decided not to proceed. But they invited the girls and their parents to the station to explain that they didn’t think it was a crime without more evidence that the images had been shared.&lt;/p&gt;
&lt;p&gt;Police appear to have concluded that only one provision of the Code applied — possession of child pornography in section 163.1 — and there was a good chance the boy could rely on the “private use” exception in &lt;a href=&#34;https://canlii.ca/t/523f&#34;&gt;R v Sharpe&lt;/a&gt;, SCC 2001.&lt;/p&gt;
&lt;p&gt;The story points to a larger gap or ambiguity in Canadian criminal law around sexual deepfakes — one that Professor Suzie Dunn (Dalhousie) helped explain to the Star.&lt;/p&gt;
&lt;p&gt;As she points out in the story and details at greater length in an informative &lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4813941&#34;&gt;article&lt;/a&gt; forthcoming in the McGill Law Journal, two Criminal Code provisions are relevant to sexual deepfakes: the prohibition in section 162.1 on non-consensual distribution of intimate images (NCII) and the prohibition in section 163.1 on making, distributing, or possessing child porn.&lt;/p&gt;
&lt;p&gt;The first offence (intimate images) applies to victims of any age. But as Dunn notes, on a plain reading, 162.1 captures only the distribution of authentic images. It prohibits sharing an “intimate image of a person”, defining this as “a visual recording of a person made by any means &amp;hellip;in which the person is nude… or is engaged in explicit sexual activity.”&lt;/p&gt;
&lt;p&gt;She notes that 162.1 does not appear to have been applied to a deepfake in any Canadian case. Doing a search of &lt;em&gt;all&lt;/em&gt; cases involving 162.1 turns up only a few hits.&lt;/p&gt;
&lt;p&gt;But as Dunn also notes, a Quebec &lt;a href=&#34;https://canlii.ca/t/k28rp&#34;&gt;court&lt;/a&gt; has applied the child porn provision in the Criminal Code (s 163.1) to capture the creation of a deepfake video. There is also a BC &lt;a href=&#34;https://canlii.ca/t/k34fl&#34;&gt;case&lt;/a&gt; from early 2024 in which the court applied section 163.1 where the accused created images using an app call ‘DeepNude’ and shared them with the victim and her friends. (Both are sentencing cases.)&lt;/p&gt;
&lt;h3 id=&#34;was-it-private-use&#34;&gt;Was it private use?&lt;/h3&gt;
&lt;p&gt;To be clear, section 163.1 appears to capture deepfake porn involving persons under 18 because it defines ‘child pornography’ to mean&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;a photographic… or other visual representation, whether or not it was made by electronic or mechanical means … that shows a person who is or is depicted as being under the age of eighteen years and is engaged in or is depicted as engaged in explicit sexual activity.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words, the image doesn’t have to be of the person him or herself. It can be an image that depicts them. But they have to be under 18.&lt;/p&gt;
&lt;p&gt;In the Toronto high school case, the boy clearly created child pornography within the meaning of 163.1. The question is whether his possession of it fell within the “private use” exception in Sharpe.&lt;/p&gt;
&lt;p&gt;In that case, the Supreme Court held that to avoid an unjustifiable limit of free expression under the Charter, a defence of “private use” had to be read into the child porn offence provisions in 163.1. It contemplates two exceptions.&lt;/p&gt;
&lt;p&gt;The first involves “the possession of expressive material created through the efforts of a single person and held by that person alone, exclusively for his or her own personal use.” The second involves recordings of lawful sexual activity for private use “created with the consent of those persons depicted.”&lt;/p&gt;
&lt;p&gt;In the Star article, Dunn queries whether the first exception would apply here, since the boy would not have created the image by himself — but by relying on an AI app, which likely entails storage of the image on company servers.&lt;/p&gt;
&lt;p&gt;Again, police or Crown probably concluded that it would be risky to proceed with a prosecution under 163.1 without clearer evidence that the boy had shared the images — thus taking him out of the Sharpe exception (without any debate about AI and company servers).&lt;/p&gt;
&lt;h3 id=&#34;are-deepfakes-not-intimate-images-under-the-code&#34;&gt;Are deepfakes not intimate images under the Code?&lt;/h3&gt;
&lt;p&gt;But I want to pick up another thread in Dunn’s comments on the gap in the Code on deepfakes — one that pertains to the other provision at issue, the prohibition on non-consensual sharing of intimate images of persons of any age.&lt;/p&gt;
&lt;p&gt;I agree that on a plain reading of 162.1 of the Criminal Code, the intimate images must be of the person themselves. But the Supreme Court of Canada has endorsed departures from the principle of strict construction in criminal law where a narrow reading would give rise to arbitrariness or defeat the larger aim or purpose of the provision.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;https://canlii.ca/t/1ftl2&#34;&gt;R v Paré&lt;/a&gt; (SCC 1987), the accused murdered a boy two minutes after committing an indecent assault against him. A provision still found in the Code (231(5)) states that &amp;ldquo;murder is first degree murder in respect of a person when the death is caused by that person &lt;em&gt;while committing&lt;/em&gt;” indecent assault or other offences. Paré argued that because it happened two minutes later, the murder was not caused ‘while committing’ the assault — and he should be entitled to a literal reading. For centuries, courts have applied the principle of strict construction in criminal law.&lt;/p&gt;
&lt;p&gt;The Court held that it was time to update the doctrine. The original reasons for it (many offences resulting in capital punishment) have been “substantially eroded”. Ambiguities should still be settled in favour of the accused, since criminal penalties are severe. But the question should now be whether “the narrow interpretation of ‘while committing’ is a reasonable one, given the scheme and purpose of the legislation.”&lt;/p&gt;
&lt;p&gt;The narrow reading wasn’t reasonable. We couldn’t assume Parliament meant to limit the meaning of ‘while committing’ to ‘simultaneously,’ because, as Justice Wilson held, doing so would result in drawing arbitrary lines between when the assault ended and the murder began. She also held that a wider reading (one that includes a murder immediately following an assault) would be the one that “best expresses the policy considerations that underlie the provision”, i.e., more serious punishment (first degree) for more serious conduct.&lt;/p&gt;
&lt;h3 id=&#34;should-paré-apply-here&#34;&gt;Should Paré apply here?&lt;/h3&gt;
&lt;p&gt;We have the same disconnect with larger purposes and arbitrariness if we read 162.1 strictly — to apply only to real images.&lt;/p&gt;
&lt;p&gt;One might argue that the purpose of 162.1 is to prevent not simply the non-consensual distribution of intimate images, but violations of a person’s &lt;a href=&#34;https://www.yalelawjournal.org/article/sexual-privacy&#34;&gt;sexual privacy&lt;/a&gt; or integrity through the sharing of intimate images. If one could circumvent the application of 162.1 by merely doctoring a real image of one’s partner &lt;em&gt;nude&lt;/em&gt; before posting it online — allowing one to say “but it isn’t actually her body” — that would make little sense.&lt;/p&gt;
&lt;p&gt;Put another way, the question is whether 162.1 makes it offence to share intimate pictures only of a person him or herself — or also what &lt;em&gt;looks&lt;/em&gt; to be him or her. If the offence doesn’t include the latter, how do we distinguish between a grainy picture of you good enough to make out and a doctored picture of you that seems real enough to be convincing? Why would non-consensual distribution of the one be criminalized and not the other?&lt;/p&gt;
&lt;p&gt;One reason might be that in the one case, a person consented to the creation of the image but not the distribution; in the other case, they consented to neither.&lt;/p&gt;
&lt;p&gt;But the gravamen of the offence lies in the non-consensual distribution of an intimate image. Do we not find the same gravamen in the sharing of a deepfake? Is the culprit not trying to do the same thing: compromise the victim’s sexual integrity through exposure?&lt;/p&gt;
&lt;p&gt;We might add that while section 162.1 clearly contemplates the distribution of intimate images a person consented to have taken of them, it doesn’t require this. The definition in 162.1(2) does say “intimate image means a visual recording of a person made by any means including…” Those means could include AI. So why does the image itself have to include only images of the person themselves? After all, every digital image is doctored to some degree by our devices.&lt;/p&gt;
&lt;h3 id=&#34;private-law-remedies&#34;&gt;Private law remedies?&lt;/h3&gt;
&lt;p&gt;Dunn’s forthcoming McGill &lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4813941&#34;&gt;paper&lt;/a&gt; notes that various provinces (aside from Ontario) have passed tort legislation making the non-consensual distribution of intimate images actionable without proof of damages. And as she points out, all are worded in ways that clearly capture deepfakes. For example, in BC’s act, intimate image “means a visual recording or visual simultaneous representation of an individual, whether or not the individual is identifiable and whether or not the image has been altered in any way, in which the individual is or is depicted as…” engaged in sexual activity, nude or “nearly nude.”&lt;/p&gt;
&lt;p&gt;Manitoba’s act was amended in 2024 to be more explicit about deepfakes, adding as a defined term &amp;ldquo;fake intimate image&amp;rdquo;, which means “any type of visual recording … that in a reasonably convincing manner, falsely depicts an identifiable person (i) as being nude or exposing their genital organs, anal region or breasts, or (ii) engaging in explicit sexual activity.”&lt;/p&gt;
&lt;p&gt;These provincial statutes set out various ways to try to have an image taken down or deleted once circulated. Orders against platforms, third-parties, search engines. All of them are potentially helpful, but how helpful (or realistic) is unclear. The federal Online Harms Act in Bill C-63 (which just died on the order paper, with the proroguing of Parliament) would have placed a host of obligations on platforms to prevent circulating NCII or take them down. I expect that bill will be reprised at some point.&lt;/p&gt;
&lt;p&gt;A cursory search on Canlii for cases applying these statutes uncovers a few dozen cases mostly seeking monetary damages for threats to distribute or posting of NCII. The focus appears to be on money rather than removal of the images. And to my knowledge, none involve deepfakes.&lt;/p&gt;
&lt;p&gt;It may be too early to assess whether tort law will be an effective tool for curbing the use of AI to create and share sexual deepfakes. But soon, I suspect, both tort and criminal law provisions will begin to be tested on this front.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why TikTok’s challenge to the order to leave Canada will fail - and how</title>
      <link>https://www.robertdiab.ca/posts/tiktok-challenge/</link>
      <pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.robertdiab.ca/posts/tiktok-challenge/</guid>
      <description>&lt;p&gt;This past November, the federal government ordered TikTok’s Canadian subsidiary to wind up its operations in Canada, though it didn’t ban the platform itself. The power to make this order is found in the &lt;a href=&#34;https://laws-lois.justice.gc.ca/eng/acts/i-21.8/page-1.html&#34;&gt;Investment Canada Act&lt;/a&gt;, which allows the Minister of Innovation, Science, and Industry to recommend to the Governor in Council that a foreign company be wound up on the basis that allowing it to continue here “would be injurious to national security.”&lt;/p&gt;
&lt;p&gt;In a &lt;a href=&#34;https://www.canada.ca/en/innovation-science-economic-development/news/2024/11/government-of-canada-orders-the-wind-up-of-tiktok-technology-canada-inc-following-a-national-security-review-under-the-investment-canada-act.html&#34;&gt;press release&lt;/a&gt; in November, Industry Minister François-Philippe Champagne said only that “The decision was based on the information and evidence collected over the course of the review and on the advice of Canada&amp;rsquo;s security and intelligence community and other government partners.”&lt;/p&gt;
&lt;p&gt;The fact that TikTok having offices in Vancouver and Toronto would be injurious to our national security is something we’re being asked to take on faith. I mused about what the reasons could be &lt;a href=&#34;https://theconversation.com/the-reasons-for-shutting-down-tiktok-in-canada-appear-tenuous-at-best-243233&#34;&gt;here&lt;/a&gt;, but I could only speculate.&lt;/p&gt;
&lt;p&gt;The latest chapter in this story is TikTok’s &lt;a href=&#34;https://sf16-va.tiktokcdn.com/obj/eden-va2/hkluhazhjeh7jr/2024.12.05%20-%20TTCI%20v%20Canada%20-%20Notice%20of%20Application.pdf&#34;&gt;challenge&lt;/a&gt; of the wind-down order in Federal Court, filed in December. TikTok alleges that the Minister’s recommendations and the Governor in Council’s decision to issue the order involved procedural unfairness, were unreasonable, were driven by improper purposes, and were grossly disproportionate in their impact (affecting hundreds of employees and some 250,000 contracts with Canadian advertisers).&lt;/p&gt;
&lt;p&gt;But at the very end of their filing, TikTok Canada asks for disclosure “of all materials in the possession of the Minister, the Public Safety Minister and the GIC” when making the decisions to move forward with the ban. This raises two questions.&lt;/p&gt;
&lt;p&gt;Will the government have to disclose this material? And can TikTok Canada make a case for the order being improper in some way without the government having to disclose this material?&lt;/p&gt;
&lt;p&gt;The government hasn’t responded yet, but we can get a sense of what is likely to unfold by looking at what happened in a recent case involving China Mobile Communications Group. What the government did there it is likely to do here.&lt;/p&gt;
&lt;p&gt;In 2021, Minister Champagne recommended that China Mobile’s Canadian subsidiary be wound up and the Governor in Council issued that order. Notably, the preamble to the order offers more specifics as to why it was being issued (as revealed in a case discussed below). The main concerns were:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;a) that China Mobile and its subsidiaries and affiliates may be subject to the influence or demands of, or control by, a foreign government;&lt;/p&gt;
&lt;p&gt;b) that China Mobile and its subsidiaries and affiliates may disrupt or otherwise compromise Canadian critical telecommunications infrastructure; and&lt;/p&gt;
&lt;p&gt;c) that China Mobile and its subsidiaries and affiliates may gain access to highly sensitive telecommunications data and personal information that could be used for non-commercial purposes such as military applications or espionage.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(To my knowledge, there was no equivalent to this in the order against TikTok.)&lt;/p&gt;
&lt;p&gt;China Mobile challenged the order. It made some of the same arguments TikTok is making - that the security review of the company was motivated by improper purposes, the final decision was lacking an evidentiary basis, and it was based on the wrong test (‘might be’ injurious rather than ‘would be’).&lt;/p&gt;
&lt;p&gt;The company’s challenge to the removal order also contained a request that the government be made to disclose documents used in the decision to issue the order.&lt;/p&gt;
&lt;p&gt;In response to the disclosure request, the government issued a certificate under section 39 of the Canada Evidence Act to assert the cabinet confidentiality over the documents. China Mobile then challenged the validity of that certificate.&lt;/p&gt;
&lt;p&gt;While it was waiting for a hearing on the certificate, the company sought a stay of the removal order. This entailed showing that it would suffer “irreparable harm” if a stay were not granted and the harm would outweigh harm to the public. The harm alleged here were the many job losses and lost contracts.&lt;/p&gt;
&lt;p&gt;The Federal Court &lt;a href=&#34;https://canlii.ca/t/jlvfs&#34;&gt;held&lt;/a&gt; in late 2021 that China Mobile would suffer irreparable harm without a stay of the removal order, but it wouldn’t outweigh the harm to the public in allowing them to remain in Canada. This is as close as a court in Canada appears to have come to assessing the substance of the security concerns motivating the removal of Chinese owned tech companies.&lt;/p&gt;
&lt;p&gt;In his reasons (beginning at paragraph 88), Chief Justice Crampton held that the government had provided “some evidence to justify their concerns regarding CMI Canada’s facilitation of espionage and foreign interference activities in Canada by the People’s Republic of China.” This included various third-party threat assessments cited in the judgment. These do little more than repeat what are essentially speculative concerns, but I digress.&lt;/p&gt;
&lt;p&gt;Then in early 2022 the Federal Court &lt;a href=&#34;https://canlii.ca/t/jmf99&#34;&gt;held&lt;/a&gt; that the assertion of cabinet confidentiality over other documents in this case was valid.&lt;/p&gt;
&lt;p&gt;China Mobile appealed this ruling and, in late 2023, the Federal Court of Appeal &lt;a href=&#34;https://canlii.ca/t/k0hk2&#34;&gt;upheld&lt;/a&gt; it. The government did all it needed to do under section 39 by attaching a schedule to the certificate describing the date of correspondence between the Ministers of Industry and Public Safety and the fact the documents at issue were (as the schedule put it) “used for or reflecting communications or discussions between ministers of the Crown on matters relating to the making of government decisions or the formulation of government policy.”&lt;/p&gt;
&lt;p&gt;And that is where the trail ends for China Mobile, as far as I can tell (it &lt;a href=&#34;https://www.biv.com/news/technology/chinese-mobile-phone-giant-pulling-out-canada-amid-security-concerns-8266448&#34;&gt;closed operations&lt;/a&gt; in BC in early 2022). Without obtaining disclosure of the government’s reasons for having the concerns about national security set out in the preamble to the order, China Mobile couldn’t establish the impropriety (procedural unfairness, unreasonableness) of the decision to issue the order.&lt;/p&gt;
&lt;p&gt;To put this another way, the fact that the government can rely on secret information and shield from judicial oversight the reasons for or the manner of arriving at the decision to make the order does not mean it was unfair, involved improper purposes, and so on.&lt;/p&gt;
&lt;p&gt;The whole framework in the Investment Canada Act is constructed so as to allow the government to issue an order directing a foreign company to leave Canada based on a belief that it would otherwise be injurious to national security — and the reasons for that belief can remain confidential.&lt;/p&gt;
&lt;p&gt;The judge in the China Mobile trial court &lt;a href=&#34;https://canlii.ca/t/jmf99&#34;&gt;decision&lt;/a&gt; on disclosure comments on this conundrum directly:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The applicants, and the Court, may have nothing to refer to in the assessment of the reasonableness of the Order, other than the Order itself. I am not, however, persuaded that this evidentiary vacuum arises from an improper exercise of authority. Rather, it arises from the nature of the proceedings and the confidences claimed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;At the end of the day, on a challenge to these orders, the government need only show that certain steps were taken: the Industry Minister consulted the Public Safety Minister, a belief was formed, and recommendations were made to the Governor in Council. Again, we have to take it on faith that the belief was reasonable and the decision to order a company like TikTok to leave did not involve improper purposes.&lt;/p&gt;
&lt;p&gt;I suspect that TikTok Canada’s challenge to the order is just a means of buying time — possibly until a change of policy around TikTok down south? Or is that too late? Time will tell.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Are your texts still private when police hijack your recipient’s identity?</title>
      <link>https://www.robertdiab.ca/posts/campbell/</link>
      <pubDate>Sat, 21 Dec 2024 00:00:00 +0000</pubDate>
      
      <guid>https://www.robertdiab.ca/posts/campbell/</guid>
      <description>&lt;p&gt;In its decision in &lt;a href=&#34;https://canlii.ca/t/k87w6&#34;&gt;R v Campbell&lt;/a&gt; earlier this month, the Supreme Court of Canada revisited an issue it had dealt with in &lt;a href=&#34;https://www.canlii.org/en/ca/scc/doc/2017/2017scc59/2017scc59.html?resultId=faef0cd91b884515827efd6bf20971c6&amp;amp;searchId=2024-12-22T06:40:03:043/07eba98359534456af7c4cf4bc960fa4&#34;&gt;R v Marakah&lt;/a&gt; (2017), but with a twist. In that case, the Court held that a person can retain a privacy interest in a text they send, despite losing control of it in the hands of a recipient. Police had read the sender’s text when they searched the recipient’s phone incident to arrest. In this case, upon seizing the recipient’s phone, police saw new texts coming in on the lock screen and began to respond to them pretending to be the recipient.&lt;/p&gt;
&lt;p&gt;Campbell addresses a number of issues, none of them entirely new, but all of them interesting and in need of further clarity. Did police conduct an ‘interception,’ engaging the wiretap provisions of the Criminal Code, when they hijacked a phone in this way? Were police authorized to search the phone as part of the recipient’s arrest, or were they conducting a different investigation once they took over the phone? Did the drug supplier sending the messages give police cause to carry out a warrantless search due to exigent circumstances, given his eagerness to quickly offload a quantity of heroin laced with fentanyl?&lt;/p&gt;
&lt;p&gt;In one sense, none of this should concern anyone outside of the drug trade. But in another sense, the Court here is writing the latest chapter in a larger story about the boundaries of digital privacy, or to put it in highfalutin terms, the boundaries of the digital self.&lt;/p&gt;
&lt;p&gt;My purpose in this post is to highlight what stands out to me about the case, having surveyed Supreme Court jurisprudence on section 8 &lt;a href=&#34;https://www.robertdiab.ca/books/search.html&#34;&gt;extensively&lt;/a&gt;, including Marakah (2017) and &lt;a href=&#34;https://www.canlii.org/en/ca/scc/doc/2019/2019scc22/2019scc22.html?resultId=d9796e939d1d468ea2d988409609edac&amp;amp;searchId=2024-12-22T06:41:37:087/659439fd9c2846c8b734663cddb21d27&#34;&gt;Mills&lt;/a&gt; (2019), two cases to which Campbell forms a companion. For this reason, I won’t try to reconstruct the reasons in detail, but I will sketch the broad outlines.&lt;/p&gt;
&lt;h3 id=&#34;how-police-intruded-on-campbells-privacy&#34;&gt;How police intruded on Campbell’s privacy&lt;/h3&gt;
&lt;p&gt;Police were investigating a suspected dealer G, one of Campbell’s buyers. They obtained a warrant to search G’s residence and arrested G attempting to drive away from the house. During the arrest, he tossed two phones in the passenger seat, which police seized incident to arrest. A few minutes later, four texts appeared on the lock screen by ‘Dew’ (Campbell’s first name is Dwayne), indicating “I need 1250 for this half” and “What you gonna need that cause I don’t want to drive around with it”. Given the amount involved and their experience with the recent drug trade in Guelph, Ontario, police assumed this was likely a half ounce of heroin mixed with fentanyl, and that there was a good chance Dew would sell it elsewhere quickly, and that it was deadly. An officer began texting with Dew to arrange delivery, in an exchange that lasted over two hours involving some 35 texts. When Campbell turned up at G’s residence shortly thereafter, he was arrested and found with drugs and cash.&lt;/p&gt;
&lt;h3 id=&#34;campbell-at-trial&#34;&gt;Campbell at trial&lt;/h3&gt;
&lt;p&gt;Campbell argued at trial that he didn’t send the first four texts, which contained the offer to supply heroin. He only sent the texts that followed, sorting out details about delivery. The decision is silent on this point, but I query whether Campbell was trying to place himself on one side of the line drawn in &lt;a href=&#34;https://www.canlii.org/en/ca/scc/doc/1997/1997canlii313/1997canlii313.html?resultId=105019a07fd64920a4313ae0883beae8&amp;amp;searchId=2024-12-22T06:42:01:881/8d4724799fad4321a88295b5f6d6311c&#34;&gt;R v Greyeyes&lt;/a&gt; (SCC 1997), where the Court held that a person aiding a purchaser is not a party to trafficking. The Court also found in that case that a person who aids both the buyer and the seller is a party to trafficking. At the very least, that’s what Campbell appears to have done here.&lt;/p&gt;
&lt;p&gt;Campbell claimed that by entering the conversation, police had interfered with his privacy and had conducted what amounted to an interception of a private communication under Part VI of the Code, requiring a warrant. The trial judge cited Marakah but held that Campbell didn’t have a reasonable privacy interest in this exchange because it “did not reveal any personal or biographical information” about Mr. Campbell and contained only “mundane comments that . . . could have been overheard on a public bus”. But even if it were private, the search was authorized under section 11(7) of the Controlled Drugs and Substances Act, which allows for a search in exigent circumstances.&lt;/p&gt;
&lt;h3 id=&#34;campbell-on-appeal&#34;&gt;Campbell on Appeal&lt;/h3&gt;
&lt;p&gt;The Ontario Court of Appeal held that Campbell did have a reasonable privacy interest in the exchange, because the texts were not “mundane,” but about a drug deal, “something one might make efforts to prevent from being overheard on a bus” – a rationale the Supreme Court would take issue with. Justice Trotter did not deal with the question of whether the exchange was an interception. He affirmed that there were exigent circumstances supporting the use of 11(7) of the CDSA. But a key facet of his ruling is his reading of Mills. A matter of dispute in the case law and commentary since Mills was decided is whether that case contains a majority holding, and if so what it holds.&lt;/p&gt;
&lt;p&gt;Briefly, in Mills, police pretended to be a 14 year-old-girl and exchanged email and Facebook messages with the accused, resulting in charges of child luring. Justice Brown, writing for himself and Justices Abella and Gascon, found that an older man could not have a reasonable privacy interest in an online exchange with a 14-year-old girl he didn’t know. Justice Karakatsanis, for herself and Wagner CJ, held that the conversation did not involve an interference with privacy since it was not a surreptitious recording of a conversation (as in &lt;a href=&#34;https://www.canlii.org/en/ca/scc/doc/1990/1990canlii150/1990canlii150.html?resultId=d15e48ea590648c8a623fd8ba4dac469&amp;amp;searchId=2024-12-22T06:42:36:829/899d30b49982459497d20d9f3133ff4e&#34;&gt;R v Duarte&lt;/a&gt;, 1990), but one carried out in digital rather than purely oral form (i.e., this was simply a conversation with an undercover officer, which is not a search). Justice Moldaver held that both sets of reasons were “sound in law”. Some courts and commentators had assumed this meant that the Brown opinion formed the majority.&lt;/p&gt;
&lt;p&gt;Justice Trotter here was careful to describe the ‘majority’ opinion in Mills as comprising both Karakatsanis and Brown’s opinions (since the two together form the basis for dismissing the appeal), but Brown and Moldaver’s reasons forming the plurality opinion. Justice Trotter distinguishes what happened in Campbell from Mills by pointing to Karakatsanis’ holding that police did not interfere with a private conversation since they were in on it from the outset. Here, Trotter notes, they “insinuated” themselves into it.&lt;/p&gt;
&lt;h3 id=&#34;majority-opinion-at-the-scc-was-it-private&#34;&gt;Majority opinion at the SCC: was it private?&lt;/h3&gt;
&lt;p&gt;At the Supreme Court, Justice Jamal, writing for himself and Chief Justice Wagner, along with Justices Kasirer and O’Bonsawin, affirmed the appeal court’s holding but offered different reasons on two key points.&lt;/p&gt;
&lt;p&gt;Justice Jamal held that Campbell’s exchange with police was private not because it was “something one might make efforts to prevent from being overheard on a bus” as Justice Trotter had held, but because of the nature of text messages per se. Texting is a form of communication we expect to be free from state interference altogether. And we have this expectation because they have the potential to reveal private information.&lt;/p&gt;
&lt;p&gt;Justice Jamal’s analysis of Campbell’s privacy in the exchange largely replicates the one in Marakah, affirming the Court’s holding there that a loss of control over data or communication in a recipient’s possession does not render a sender’s privacy interest unreasonable. But the reasoning here contains fewer qualifications about texts being private. Whereas in Marakah, they can be private, the holding here comes close to asserting that texts are prima facie private, given our normative assumptions about them.&lt;/p&gt;
&lt;p&gt;Justice Rowe agreed with Jamal’s reasons on this point without reservation, and the dissenting opinion of Justices Martin and Moreau (joined by Karaktasanis) also affirms privacy in text messages in a broad and unqualified sense (“Conversations that take place over text messaging promise participants a high degree of privacy and are capable of revealing a great deal of personal information.”) Only Justice Côté’s concurring opinion raises the point that Marakah didn’t create a ‘categorical rule’ that all texts attract a reasonable privacy interest. But given the view of eight other members of the Court, it may be that Campbell now stands for the contrary: all texts are presumptively private. And this in itself may be the most significant aspect of the decision.&lt;/p&gt;
&lt;p&gt;The eight members of the Court (aside from Côté) also agreed that the intrusion into Campbell’s conversation was not authorized by the power to search incident to G’s arrest, since it was not ‘truly incidental’ to the reason for arresting G. The officer’s purpose in hijacking the conversation was to conduct a search of Dew for a different offence (trafficking) from those involving G. A small point, largely turning on the facts here. But one likely to be applied in future text message hijacking cases (already an emerging sub-genre as the citations in this case attest).&lt;/p&gt;
&lt;h3 id=&#34;the-mills-situation&#34;&gt;The Mills situation&lt;/h3&gt;
&lt;p&gt;Another tidbit that stands out to me is Justice Jamal’s discussion of Mills. A question before the Court here was whether Mills had created an exception to Marakah to the effect that where police suspect that a “relationship involves a crime,” communications are not private. Justice Jamal canvasses Mills in some detail to note that both Karakatsanis and Brown’s opinions affirmed Marakah. More to the point, Jamal was adamant that “there was no majority decision in Mills.” When Justice Moldaver asserted that both Karakatsanis and Brown’s opinions were “sound in law,” this did not result in Brown’s opinion becoming the majority holding – creating a Mills exception to Marakah. In other words, Justice Jamal was keen to reject the notion that texts are private unless the content or relationship itself is criminal in nature.&lt;/p&gt;
&lt;p&gt;So, while Justice Jamal concludes this portion of the decision by asserting: “It is thus not necessary to decide whether Mills is properly characterized as creating an ‘exception’ to Marakah or as departing from the content‑neutral approach to s. 8 of the Charter” – what I think he’s really done is settled the debate about Mills and reduced the provocative opinions in that case to so much obiter.&lt;/p&gt;
&lt;h3 id=&#34;was-this-a-wiretap&#34;&gt;Was this a wiretap?&lt;/h3&gt;
&lt;p&gt;Justice Jamal deals at some length with whether hijacking the phone constituted a wiretap, but he isn’t entirely clear about his reason for finding that it wasn’t. After canvassing the wiretap scheme and noting the Court’s holding in Telus (but not distinguishing it), he asserts: “in my view, Part VI is not engaged here because the police did not use a device employing intrusive surveillance technology.” He notes at one point that Part VI contemplates the use of “a separate ‘device or apparatus’ that effects the interception by surreptitious technological means”.&lt;/p&gt;
&lt;p&gt;I take Justice Jamal to mean here that police did not carry out an interception of a private conversation with Campbell because while Cambell didn’t know he was talking to an officer, he knew that his speech was being recorded. I think this makes good sense. The thrust of Justice La Forest’s concern in Duarte (1990) was that the risk of being recorded by the state was a risk of a different order from your interlocutor turning out to be a tattletale. We can’t be assumed to accept the risk of being recorded whenever we speak, since the state could now be doing that at any time. But ever since we began texting, we recognized and accepted the risk that any text we might send could be shared.&lt;/p&gt;
&lt;p&gt;Perhaps Justice Jamal assumes here that the risk of the interlocutor turning out to be a state agent is not a risk of a different order from the risk of our texts being turned over to the state by our recipient (which would also engage a privacy interest, a topic on which I happen to have &lt;a href=&#34;https://www.robertdiab.ca/papers/Pol-Receipt.pdf&#34;&gt;written recently&lt;/a&gt;. Justice Jamal reiterates at the close of this segment that while police conduct may not have involved an interception under Part VI, “this was prima facie an intrusion upon Mr. Campbell’s reasonable expectation of privacy.”&lt;/p&gt;
&lt;p&gt;To jump ahead to the dissent on this point, Justices Martin and Moreau (joined by Karakatsanis) offered a contrary view in a lengthy segment of their opinion — holding that what police did here should be construed as an interception under Part VI of the Code. Their reasons are twofold. An interception doesn’t require a separate device; Justice Jamal, they believe, misconstrues the definition in the Code. They also cite the Court’s broader definition in R v Jones (2017): an “interception relates to actions by which a third party interjects itself into the communication process in real-time through technological means.” Their second reason is implicit in their argument: while Campbell knew he was conversing in writing — and thus wasn’t being surreptitiously recorded — he didn’t know he was being recorded by the state. This latter rationale would seem to conflict with Karakatsanis’ opinion with Chief Justice Wagner in Mills, where she found the exchange with an undercover officer did not constitute an interception or a privacy intrusion because even though Mills didn’t know he was conversing with a state agent, he did know he was being recorded.&lt;/p&gt;
&lt;h3 id=&#34;were-there-in-fact-exigent-circumstances-here&#34;&gt;Were there in fact exigent circumstances here?&lt;/h3&gt;
&lt;p&gt;Put another way, if hijacking the phone constituted a search (since it interfered with a reasonable privacy interest), was the search reasonable? It was reasonable if it was authorized by law (&lt;a href=&#34;https://www.canlii.org/en/ca/scc/doc/1987/1987canlii84/1987canlii84.html?resultId=d70edd2b826d406abcc6b92cd59f452b&amp;amp;searchId=2024-12-22T06:43:19:283/1eecf8f66e2e4cca9e4fababa3fca3d9&#34;&gt;R v Collins&lt;/a&gt;, 1987). All three levels of court affirmed that this search was authorized by law, namely section 11(7) of the CDSA.&lt;/p&gt;
&lt;p&gt;The remainder of Justice Jamal’s majority opinion deals with the exigency question, affirming the findings below that the requirements of 11(7) were made out here. I don’t believe he adds much to the Court’s earlier decision in &lt;a href=&#34;https://canlii.ca/t/h1tk4&#34;&gt;Paterson&lt;/a&gt; (2017) glossing this provision. And I don’t share the concern on the part of the dissent or by other commentators on this case that a finding of exigency here will vastly expand the scope of that power. I think the finding that there was an immediate and real public safety concern in this case largely turns on the facts. The first four texts make explicit that the Dew was in a rush to be rid of his supply. There was a good reason to believe it contained fentanyl. And the danger that someone could die that day from this supply was real.&lt;/p&gt;
&lt;p&gt;As Justice Jamal notes, there had to be a “reasonable probability of the claimed exigency,” and in this case the trial judge’s finding on this point was sound. Police might have been able to obtain a telewarrant, the trial judge reasoned, but Dew was impatient and might have sold the drugs by then. For the majority of the Supreme Court, no error in logic here.&lt;/p&gt;
&lt;p&gt;Justices Martin and Moreau (along with Karakatsanis) in dissent held that the circumstances did not give rise to exigency under 11(7), because the danger was only hypothetical. Dew might sell to a buyer who in turn might provide a quantity of fentanyl to a user, but whether and when that would happen was all too speculative to meet the test of a probability of an imminent risk to public safety in 11(7). And as a consequence, the majority’s holding that it did meet this test will water down the requirements of 11(7). It will allow police to carry out warrantless searches in cases involving dangerous drugs too readily – relying on the dangerousness of the drug to create a sense of urgency that isn’t there. But as Justice Jamal and Rowe make clear in their respective opinions, probable grounds to believe danger is imminent does not require a certainty or even a balance of probabilities; simply a reasonable probability. &lt;/p&gt;
&lt;p&gt;Again, I admire the sentiment – the sense of caution – in the Martin Moreau dissent, but I think the exigency issue in this case is largely about the particular wording of those first four texts. They were golden facts for the Crown. Not likely to be repeated. But that isn’t to say that Campbell won’t be a frequent citation for the Crown on section 8. It will also be a key case for defence.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
