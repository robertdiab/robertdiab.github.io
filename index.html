<!DOCTYPE html>
<html lang="en-us"><head>
	<meta name="generator" content="Hugo 0.81.0" />
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GXV01KRXE5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GXV01KRXE5');
</script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
<meta name="description" content="A blog about law and technology">


<meta name="keywords" content="technology law policy AI privacy digital communication">


<link rel="stylesheet" media="screen and (min-width: 441px)" href="/css/widescreen.css">

<link rel="stylesheet" media="screen and (max-width: 440px)" href="/css/smallscreen.css">

  <title>Robert Diab</title>

  <link rel="alternate" type="application/rss+xml" href="https://www.robertdiab.ca/index.xml" title="Robert Diab" />
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png">
  <link rel="manifest" href="/images/favicon/site.webmanifest">
  <link rel="mask-icon" href="/images/favicon/safari-pinned-tab.svg">
  <link rel="shortcut icon" href="/images/favicon/favicon.ico">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-config" content="/images/favicon/browserconfig.xml">
  <meta name="theme-color" content="#ffffff">


</head>
<body>
      <div class="hdsection">

<div class="container">
<header>







<div class="sitelogo-field">
<a href=" / "><h1>Robert Diab</h1></a>
</div>
















<nav>
    <ul>
        <li><a href="/commentary" style="">Commentary</a><p1>|</p1></li>

        <li-2><a href="/publications" style="">Papers/Books</a></li-2>


    </ul>
</nav>



</header>
</div>
</div>

      <div class="sidenav">








<span class="smallnav"><p>Professor of law at Thompson Rivers University, writing about law and technology. More <a href="https://www.tru.ca/law/faculty-staff/faculty/robert-diab.html" style="">here</a></p></span>

<span class="smallnav"><p>Follow on <a href="https://robertdiab.substack.com" style="">Substack</a> & <a href="https://bsky.app/profile/robertdiab.bsky.social" style="">Bluesky</a></p></span>

<span class="navtitle">Recent posts</span><br>
<span class="smallnav">
<div class=recent-posts>

  

<a href="https://www.robertdiab.ca/posts/ai-liability/">When AI Turns Deadly: Are Model Makers Responsible?<div class=space> </div></a><br>

  

<a href="https://www.robertdiab.ca/posts/c2backgrounder/">Bill C-2 Backgrounder - the missing manual!<div class=space> </div></a><br>

  

  </div>
</span>

<span class="navtitle-earlier">Earlier posts</span><br>
<span class="earlier-posts"><a href="/posts" style="">By date</a></span>
<br>
<span class="earlier-posts"><a href="/tags/" style="">By topic</a></span>
<br>
<span class="earlier-posts"><a href="/index.xml" style="">RSS Feed</a></span><br>
</div>

        <div class="content">

<div class=post-content>

  

<div class=post-title><a href="https://www.robertdiab.ca/posts/authorship-ai/">Authorship After AI</a></div>

  
            <span class="post-date">
              Sep 19, 2025
            </span>

          

<p><p><img src="/images/Post-pic.jpg" alt="image alt *"></p>
<p>A new article in AI Magazine draws an illuminating comparison between what AI is doing to writing and what photography did to art in the 1840s. It helps to make sense of a question many of us are thinking about more often: does increasing reliance on AI signal the end of writing?</p>
<p>The insights in this piece resonate with me, given the quantum leap in my own use of AI over the past few months.</p>
<p>I’m now making such frequent use of it — integrating it into my research, writing, and editing — that it has me wondering what’s really happening.</p>
<p>As I describe in a piece forthcoming in the CBA’s National Magazine, I’ve been dipping in and out of Claude, ChatGPT, and Perplexity constantly — to get a quicker lay of the land on new topics, reword sentences, and tighten drafts. But the pace and intensity feel like a transformation as momentous as the shift from typewriter to computer, or from paper-based research to the internet.</p>
<p>To be clear, I’m not using AI to create texts. But using it more often to edit, it sometimes causes me to think about my claim to authorship. At what point does a suggestion — or re-write of a paragraph — mean it’s no longer me?</p>
<p>In “<a href="https://onlinelibrary.wiley.com/doi/full/10.1002/aaai.70022">Reclaiming authorship in the age of generative AI: From panic to possibility</a>,” Mohsen Askari argues that we need to abandon the notion that “authorship is defined by the absence of tools” — that using AI contaminates the purity of writing.</p>
<p>He sees AI as part of a continuum of tools from the pen to the typewriter to the reference manager. His central claim is provocative: “[w]hat matters is not whether help was involved, but whether the author stands behind the final work.”</p>
<h3 id="why-ai-is-like-early-photography">Why AI is like early photography</h3>
<p>The sharpest part of his piece is the analogy to photography in France in 1839. Painter Paul Delaroche famously declared: “From today, painting is dead!” The camera’s ability to mechanically capture the world posed an existential threat to painting not unlike our response to AI in writing: “shock, suspicion, and widespread declarations of the end of a creative tradition.”</p>
<p>Early photography was dismissed as craftless. It seemed to require “no imagination, no hand, and no labour.” The prestige artists earned for mastery evaporated. Photography “democratized image-making.”</p>
<p>But painting didn’t die. It ceased to be about reproduction and exploded with creativity through abstraction and experimentation. Meanwhile, photography itself became an art form: “Mastery emerged not from the act of clicking a shutter, but from timing, framing, lighting, and selection. In short: from judgment.”</p>
<p>Askari sees the same happening with AI. Like photography, it produces results quickly and provokes fears of “fraudulence and depersonalization.” Yet using AI well involves more than typing a prompt; it requires “knowing what to ask, how to evaluate, when to refine, and when to reject.”</p>
<p>AI can produce fluent text, he notes, but fluency is “not the same as quality, insight, or originality.” The real work lies in “asking the right questions, rephrasing, discarding early results, and returning with a clearer intent.”</p>
<p>For Askari, writing with AI remains authorship when it involves real “sculpting”: “The user curates meaning. They filter the signal from the noise. Above all they remain accountable for what is kept and what is removed.”</p>
<h3 id="but-is-it-really-you">But is it really you?</h3>
<p>Askari may be stretching it too far. Surely authorship is more than “augmentation” or “curation.”</p>
<p>But he has a point: authorship can be authentic even if not every sentence is one’s own. In conversation, we often grope toward an idea only for a friend to supply the better phrasing, which we readily adopt. They give us the words; we provided the idea. The proof is that our friend doesn’t just nod but lights up with an “aha.” This is the distinction Askari seems to be after.</p>
<p>For people pressed with time, living with “interrupted attention spans,” or working in “linguistically diverse environments,” AI, he says, isn’t a “crutch or a cheat,” but a “tool that enables a different kind of flow.”</p>
<p>In the academy, the flow he describes sparks anxiety because AI makes suddenly “easier, faster, and more accessible” skills that once took years to develop: “the ability to write well, think clearly, and publish independently.”</p>
<p>We’re still aiming to cultivate these skills rather than handing them off to AI. How do we do this when AI offers to do it all for us?</p>
<h3 id="what-about-student-assignments">What about student assignments?</h3>
<p>When students hand in work with a strong trace of AI—a paper more polished than we suspect they would have written on their own—Askari urges us to question the reflexive view that AI use entails “the absence of thought.” He suggests we see the tool not as disrupting writing, but as having “supported” it.</p>
<p>The question, he writes, is not “whether AI was used, but whether the author remained present, intentional, and accountable throughout the process.”</p>
<p>This framing helps.</p>
<p>When I recently used AI to revise the opening of a piece, I wondered whether it was still my writing if I adopted the suggestion. Askari’s point is that it’s yours not because you accept AI’s wording, but because what AI is rewording is your idea.</p>
<p>If there’s a visible trace between your draft and AI’s output, then yes, you wrote it. AI only helped.</p>
<p>But what about the term paper I received last spring in one of my courses that seemed written entirely by AI? Askari would say this wasn’t authorship any more than pointing a camera out a window and clicking would be art.</p>
<p>It fails because the student had not “remained present, intentional, and accountable throughout the process.” They simply pointed and clicked. And that’s why it felt wrong.</p>
<p>We might conclude that what matters is not whether AI polished a student’s prose, but whether we can still detect presence and intentionality. Original ideas, analogies, connections.</p>
<p>The line will often be subtle. How much originality or intent is enough? How do we measure it? How do we teach students not to over-rely on AI?</p>
<p>Not easy questions. But Askari’s insights remain useful.</p>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/ai-liability/">When AI Turns Deadly: Are Model Makers Responsible?</a></div>

  
            <span class="post-date">
              Aug 30, 2025
            </span>

          

<p><p>This week, parents of Adam Raine, a California teen who committed suicide in April after a lengthy interaction with GPT-4o, <a href="https://www.theguardian.com/technology/2025/aug/27/chatgpt-scrutiny-family-teen-killed-himself-sue-open-ai">filed a lawsuit</a> against OpenAI and its CEO, Sam Altman. The case follows a <a href="https://www.nytimes.com/2024/10/23/technology/characterai-lawsuit-teen-suicide.html">suit</a> brought in late 2024 by the parents of a Florida teen, Sewell Setzer, who took his own life after engaging with a Character.AI chatbot impersonating Daenerys Targaryen from Game of Thrones.</p>
<p>In early August, ChatGPT was also implicated in a <a href="https://www.wsj.com/tech/ai/chatgpt-ai-stein-erik-soelberg-murder-suicide-6b67dbfb">murder-suicide in Connecticut</a> involving 56-year-old tech worker Stein-Erik Soelberg, who had a history of mental illness. Although the chatbot did not suggest that he murder his mother, it appears to have fueled Soelberg’s paranoid delusions, which led him to do so.</p>
<p>OpenAI and other companies have been quick to respond with <a href="https://openai.com/index/helping-people-when-they-need-it-most/">blog posts</a> and <a href="https://openai.com/index/openai-anthropic-safety-evaluation/">press releases</a> outlining steps they are taking to mitigate risks from misuse of their models.</p>
<p>This raises a larger question left unanswered in Canada after the <a href="https://ised-isde.canada.ca/site/innovation-better-canada/en/artificial-intelligence-and-data-act">Artificial Intelligence and Data Act</a> died on the order paper in early 2025, when the last Parliament ended: what guardrails exist in Canadian law to govern the harmful uses of generative AI?</p>
<p>Like the United States, Canada has no national or provincial legislation designed to impose liability on AI companies for harms caused by their products. The European Union passed an <a href="https://artificialintelligenceact.eu/ai-act-explorer/">AI Act</a> in 2024 that does impose liability for harmful AI systems.</p>
<p>But in both the EU law and the Canadian bill that was abandoned, there is a notable flaw in how liability is conceived.</p>
<p>I explored this in <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4680927">a paper I wrote</a> in late 2023, surveying early reports of harmful uses of language models (a suicide in Belgium, help with bomb-making, and other cases).</p>
<p>My article garnered some interest on SSRN but only recently appeared in print (it was <a href="https://commons.allard.ubc.ca/cgi/viewcontent.cgi?article=1372&amp;context=ubclawreview">published</a> this month). The core argument was this:</p>
<blockquote>
<p>Both [the European and Canadian AI] bills are premised on the ability to quantify in advance and to a reasonable degree the nature and extent of the risk a system poses. This paper canvases evidence that raises doubt about whether providers or auditors have this ability. It argues that while providers can take measures to mitigate risk to some degree, remaining risks are substantial, but difficult to quantify, and may persist for the foreseeable future due to the intractable problem of novel methods of jailbreaking and limits to model interpretability.</p>
</blockquote>
<p>The problem remains unresolved.</p>
<h3 id="the-only-guardrails-at-the-moment">The only guardrails at the moment</h3>
<p>The only mechanisms in Canada and the US for holding AI companies liable are laws on product liability, negligence, and wrongful death.</p>
<p>Parents in both the California and Florida cases are suing the model makers (OpenAI and Character.AI, respectively) for wrongful death, a statutory cause of action that allows family members of the deceased to sue for damages including funeral expenses, mental anguish, loss of future financial support, and companionship. Plaintiffs must show the defendant’s negligence or intentional misconduct caused the death.</p>
<p>Here, parents allege that chatbot makers were negligent in product design and failed to provide adequate warnings about risks.</p>
<p>Canadian law works in a similar way. Provinces allow wrongful death suits for a wrongful act. Damage awards in Canada are much smaller than in the US and mostly limited to quantifiable losses. But plaintiffs can also claim that a model maker was negligent in offering a harmful product, or that it was defective or lacked adequate warnings.</p>
<p>At the heart of negligence and product liability is the same question: what steps should OpenAI, Anthropic, or Google reasonably have taken to avoid harm?</p>
<p>Put another way, in making chatbots available, companies clearly owe users a duty of care. The product carries risks, and harm to users is foreseeable.</p>
<p>The key question, though, is: what is the standard of care?</p>
<p>When can OpenAI and others be said to have done enough—or not enough—to avoid harm? If the standard is “reasonably safe” rather than “absolutely safe,” when is that threshold met? And can it even be met, given the nature of these systems?</p>
<p>No one knows. But OpenAI and others are taking—and <a href="https://openai.com/index/helping-people-when-they-need-it-most/">publicizing</a>—all the steps one might predict a tort lawyer would advise them to take.</p>
<p>OpenAI admits its risk-detection mechanisms work better in shorter conversations and degrade as conversations lengthen. It is working to improve performance in longer chats.</p>
<p>It is also improving detection across different types of harmful conversations, from suicidal to criminal. It has announced plans for parental controls to let parents monitor their child’s activity, and is rolling out systems to route some conversations to human overseers who can terminate the chat and lock the user out of further access.</p>
<p>Whether these steps will be deemed sufficient—enough to absolve OpenAI and others of liability—remains to be seen.</p>
<p>Much may depend on how a model was misused, what jailbreak was employed, and whether that misuse was foreseeable.</p>
<p>In a broader sense, it is worth keeping perspective on AI risks. As tragic as these cases are, hundreds of millions of people use these tools daily, and many find them beneficial. But there are, inevitably, many ways to misuse them.</p>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/c2backgrounder/">Bill C-2 Backgrounder - the missing manual!</a></div>

  
            <span class="post-date">
              Jul 23, 2025
            </span>

          

<p><p>Over a month later, the controversy over the <a href="https://www.parl.ca/DocumentViewer/en/45-1/bill/C-2/first-reading">Strong Borders Act</a> continues.</p>
<p>Privacy experts are still sounding the alarm over the astonishing breadth of some of the new powers — allowing police to demand from a doctor, lawyer, anyone who “provides a service” information about a person’s account without a warrant; a power to compel Shaw or Google to “install equipment” that would give police or CSIS access to personal data — the list goes on.</p>
<p>Following my last <a href="https://www.robertdiab.ca/posts/strong-borders-search/">post</a> that looked in some detail at parts of the bill, the government has issued a <a href="https://www.justice.gc.ca/eng/csj-sjc/pl/charter-charte/c2_2.html">Charter statement</a> that drew <a href="https://www.youtube.com/watch?v=t6yjuEOjMPo">criticism</a> for being self-serving, even misleading. Along with others, I wrote <a href="https://www.techpolicy.press/buried-in-a-border-bill-canada-creates-major-new-search-powers-over-private-data/">opinion</a> <a href="https://www.cigionline.org/articles/canadas-lawful-access-bill-heavy-on-secrecy-light-on-accountability/">pieces</a> and spoke about the bill on <a href="https://www.michaelgeist.ca/2025/06/law-bytes-podcast-episode-236/">Law Bytes</a> and other venues.</p>
<p>But I noticed there was still some confusion and uncertainty about many aspects of the bill. Rather than wait for a Parliamentary backgrounder to appear, I decided to put together my own overview of all aspects of the bill touching on privacy — and to offer an independent assessment of them in relation to section 8 of the Charter (guaranteeing “a right to be secure against unreasonable search or seizure”).</p>
<p>The result is a paper I’ve posted to SSRN titled “<a href="https://papers.ssrn.com/abstract=5363319">Bill C-2 Backgrounder: New Search Powers in the Strong Borders Act and Their Charter Compliance</a>”.</p>
<p>I&rsquo;ve tried to provide more context than is found in the government’s Charter statement, by detailing how new powers expand on or amend those currently in force.</p>
<p>The paper looks at more controversial parts of the bill, including the whole new lawful access act contained in C-2, and declaratory provisions in the Criminal Code asserting that police don’t need a warrant for subscriber ID or an ‘information demand’ with voluntary compliance — and an indemnity for those who comply.</p>
<p>I plan to keep the paper up to date (on <a href="https://papers.ssrn.com/abstract=5363319">SSRN</a>) as the bill moves through second and third reading — and to post those updates here. Comments are welcome!</p>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/strong-borders-search/">Major new search powers in the Strong Borders Act: are they constitutional?</a></div>

  
            <span class="post-date">
              Jun 8, 2025
            </span>

          

<p><p>The Liberal’s first bill in Parliament last week proposes a raft of new search powers to give police easier access to our private data. They may turn out to be the most consequential search powers added to the Criminal Code in the past decade.</p>
<p>They have little to do with the primary aim of the bill, strengthening borders by expanding powers in customs and immigration.</p>
<p>Tucked in the middle of <a href="https://www.parl.ca/LegisInfo/en/bill/45-1/C-2">Bill C-2</a> are measures that revive long-standing aims to pass “lawful access” legislation that will make it easier for police to obtain subscriber information attached to an ISP account (with Shaw or Telus) and give police direct access to private data held by ISPs or platforms like iCloud, Gmail, or Instagram.</p>
<p>I’ve written a general overview of these powers for The Conversation <a href="https://theconversation.com/the-proposed-strong-borders-act-gives-police-new-invasive-search-powers-that-may-breach-charter-rights-258257">here</a>, and Michael Geist has a very <a href="https://www.theglobeandmail.com/opinion/article-strong-borders-act-privacy-threats-security/">informative op-ed</a> in the Globe that sets out a wider context and walks through some of the provisions in detail. If you’re new to this story, you might begin there.</p>
<p>In this post, I offer a few thoughts on the constitutionality of three key powers in the bill: the new production order for subscriber info; the new information demand power; and the provisions that compel service providers to assist police in gaining direct access to personal data.</p>
<p>This is a long post, almost 3k words. It might have been three shorter ones, but I thought I’d put it all in one post.</p>
<p>It’s meant for those looking for a deeper dive on the constitutional questions.</p>
<h3 id="what-do-you-mean-by-constitutional">What do you mean by ‘constitutional’?</h3>
<p>The larger issue here is whether these provisions will survive a challenge under section 8 of the Charter of Rights and Freedoms, guaranteeing “everyone has the right to be secure against unreasonable search or seizure.”</p>
<p>Two things to keep in mind about section 8: What is a search? And when will a search be reasonable? </p>
<p>A search for the purpose of section 8 is anything done by a state agent for an investigative purpose that interferes with a reasonable expectation of privacy in a place or thing (<a href="https://canlii.ca/t/k358f">R v Bykovets</a>).</p>
<p>A search will be reasonable where it is authorized by law, the law is reasonable, and it is carried out in a reasonable manner (<a href="https://canlii.ca/t/1ftnd">R v Collins</a>).</p>
<p>The powers created in this new bill set out authority for a search. The issue here is whether each of them sets out a ‘reasonable law’ authorizing a search.</p>
<p>(In case you’re interested, I’ve co-authored an entire book on section 8, which you can check out <a href="https://www.robertdiab.ca/books/search.html">here</a>.)</p>
<h3 id="relevant-background-production-orders-and-the-spencer-situation">Relevant background: production orders and the Spencer situation</h3>
<p>In 2004, Parliament <a href="https://www.canlii.org/en/ca/laws/astat/sc-2004-c-3/latest/sc-2004-c-3.html">created</a> what are called ‘production orders’ to give police the power to ask an internet or cellphone service provider to hand over data about digital communications, including the content of messages.</p>
<p>That power required reasonable suspicion, and it was challenged under section 8 of the Charter as being too low a standard, giving rise to an unreasonable search.</p>
<p>In 2014, the BC Supreme Court <a href="https://canlii.ca/t/gtr5r">said</a> it was too low: it should be probable grounds; the Alberta Court of Appeal <a href="https://canlii.ca/t/gdqg3">disagreed</a>: it should only be reasonable suspicion.</p>
<p>That same year Parliament passed <a href="https://www.parl.ca/LegisInfo/en/bill/41-2/C-13">Bill C-14</a>, which created a general production order requiring probable grounds (487.014) and four more specific production orders requiring only reasonable suspicion — for tracing communications (e.g., metadata attached to email or phone calls), transmission data (call or text histories); tracking data (location data); and financial data (487.015 to 487.018).</p>
<p>Meanwhile, in June of 2014, Supreme Court of Canada decided <a href="https://canlii.ca/t/g7dzn">R v Spencer</a>, which held that subscriber information attached to an IP address — the name and physical address of the person linked to it — is private, because it associates a person with their online search history. Police can’t demand it from an ISP without authority in law to do so (which may or may not involve a warrant).</p>
<p>The Court in Spencer noted (at para 11) that police had demanded the subscriber ID from Shaw without first obtaining a production order in that case — thus contemplating its use as a means for doing so.</p>
<p>But the Court did not address the question of what kind of search power would be reasonable to obtain subscriber info. After explaining why provisions in private sector legislation (PIPEDA) didn’t authorize the search, the Court simply concluded (in para 73) that “in the absence of exigent circumstances or a reasonable law,” police couldn’t lawfully search (i.e., demand) it.</p>
<p>So what remained unclear after Spencer was: what is a reasonable search law that authorizes police to make a demand for subscriber information?</p>
<p>The presumptive standard for a reasonable search in criminal law (i.e., what constitutes a “reasonable law” authorizing a search) is one involving a warrant issued on “reasonable grounds to believe” (probable grounds) that an offence has been or will be committed, rather than “reasonable suspicion.” It would seem, then, that a demand for subscriber ID should be a warrant on probable grounds.</p>
<p>Things said in Spencer support this inference. It held the privacy interest in subscriber information is high, given that it links a person to search activity that can be highly revealing. Anything less than probable grounds would not strike the right balance between law enforcement interests and personal privacy. But at least one privacy scholar <a href="https://digitalcommons.osgoode.yorku.ca/cgi/viewcontent.cgi?article=1298&amp;context=sclr">disagrees</a>.</p>
<p>In the wake of Spencer, to obtain subscriber info, police have been using the new general production order power added in 2014, requiring probable grounds. Again, this isn’t a powered tailored specifically for obtaining subscriber ID, so it’s unclear whether anything less would suffice. Police and Crown hope so. Probable grounds is a relatively high standard; why not just a warrant on reasonable suspicion?</p>
<h3 id="privacy-in-a-set-of-numbers-alone">Privacy in a set of numbers alone?</h3>
<p>And what about demanding an IP address? Sometimes police can’t get far without asking an ISP or an online platform like Instagram to reveal a user’s IP address. Did they need a warrant for this? Was an IP address on its own private?</p>
<p>In <a href="https://canlii.ca/t/k358f">R v Bykovets</a>, the Supreme Court of Canada held that an IP address is private because it readily links a person to their online activity. But the Court didn’t specify what kind of power would render a search (demand) for an IP address reasonable.</p>
<p>At para 85 of the decision, Karakatsanis J for the majority, points the production order power in section 487.015(1) of the Code (for transmission data) on reasonable suspicion as possible tool police might use here. This is obiter, since the Court is not being asked whether the use of this to demand an IP address would constitute a reasonable law. Yet we can assume that the judges in the majority think that a warrant on reasonable suspicion would suffice.</p>
<h3 id="new-production-order-in-the-strong-borders-act">New production order in the Strong Borders Act</h3>
<p>The new bill gives police and Crown what they want: a production order power tailored to making a demand for subscriber info by obtaining a warrant issued on reasonable suspicion that a federal offence has been or will be committed (a new 487.0181(2) of the Criminal Code).</p>
<p>Will this be constitutional? More specifically, a search conducted under this power will be authorized by law, but is this law reasonable?</p>
<p>There is no single test for when a law authorizing a search is reasonable under section 8 of the Charter. But the Supreme Court has generally considered four factors: whether the power relates to a criminal or regulatory offence; the state or law enforcement interest at issue; the impact on personal privacy; and the oversight and accountability safeguards.</p>
<p>Demanding subscriber info on reasonable suspicion is, I think, likely to be found unreasonable. In this case, the privacy interest is high (i.e., the online activity linked to a person’s name). Given things said about this in Spencer, this alone could favour a finding that nothing less than probable grounds is reasonable.</p>
<p>Further possible support may be found in <a href="https://canlii.ca/t/fqxmc">R v Tse</a>, which held that emergency wiretap provisions of the Code were unreasonable for failing to include a post facto notice requirement to persons affected. In this case, there’s no requirement to advise a person that they were subject to a production order, if charges do not follow. Not sure a court would view production order powers to be sufficiently analogous to wiretap provisions. But I flag it as a potential consideration.</p>
<h3 id="the-new-information-demand-power">The new “information demand” power</h3>
<p>Bill C-2 also creates a new power on the part of police to demand information. In some cases, police may only ask if a service provider has info about something. In other cases, they can demand the info itself.</p>
<p>Under a new section 487.0121 in the Code, police can ask a service provider whether they have “provided services to any subscriber or client, or to any account or identifier.” If so, police can demand to be told where and when service was provided — along with info about any other providers who may have offered the person service.</p>
<p>They can do this on reasonable suspicion alone, without a warrant.</p>
<p>Police can thus ask Shaw or Gmail things like: does this user have an account with you? Do you have an IP address or phone number associated with their account? If so, tell us where and when you provided it.</p>
<p>Why do police need this power? Aren’t police free to ask questions as part of their investigation? Is there not a distinction between a person describing to police what they know or have observed and police demanding to see it themselves? Can’t we assume that police only carry out a search when they ask for and receive private data itself?</p>
<p>Recall that a search is anything done for an investigative purpose that interferes with a reasonable expectation of privacy. Police demanding private information in the hands of a third party can constitute a search. For example, police carried out a search in Spencer by asking Shaw: whose name is attached to this IP address?</p>
<p>What is contemplated here differs in some ways but is similar in others. Police might ask simply: do you have a name (or an account) attaching to this IP address? Did you lease this IP address to a person? Or they might ask: when and where did you provide use of this IP address?</p>
<p>In some cases, depending on the question and the limited info revealed by the answer, it may not amount to a search. But in some cases it can. </p>
<p>If police have a name, or an IP or email address and they ask a dating, gambling, or porn website whether they have a user account related to any of them, a “yes” in response could be quite revealing. If a service provider can link a person to a location, or more than one, in a window of time, this could also be invasive.</p>
<p>Should this too require a warrant? We’re in genuinely new terrain here.</p>
<p>The information demand power gives police authority to go poking around the edges of our digital lives — knocking on the doors of anywhere we’ve left a digital trace — to ask questions that could readily create a clear picture of who we are and where we’ve been. All on nothing more than reasonable suspicion.</p>
<p>I can see a challenge to this power leading to a deeply divided the Supreme Court decision similar to that in <a href="https://canlii.ca/t/k358f">Bykovets</a>, where half the Court says: reasonable suspicion is enough, and the other half says no, it should require a warrant.</p>
<p>I suspect it will come down to half the Court seeing this power as too preliminary to pose a real threat to privacy and police needing some leeway to act without undue hindrance, and half the Court seeing this as too close in nature to a means of circumventing the protections around subscriber ID and IP addresses. In some cases a positive answer to the question: “does this user have an account with you?” will be all the police need to know to link a person with an extensive amount of personal data.</p>
<p>If I were a betting man, which I’m not, I would bet that a majority of the Court will find this power reasonable. (But there will be a wonderful, eloquent dissent, probably by Karakatsanis J or Martin J or maybe both, on the importance of privacy and the need for a warrant.)</p>
<p>Briefly, Bill C-2 also extends to agents of the Canadian Security Intelligence Service the ability to make an information demand on no grounds at all. But they may not target a Canadian citizen or permanent resident. Given the high state interest in these cases and the limited privacy interest engaged, this power is likely to be found reasonable.</p>
<h3 id="the-lawful-access-provisions">The lawful access provisions</h3>
<p>Bill C-2 contains a whole new statute called the “Supporting Authorized Access to Information Act,” which brings about a “lawful access” regime for private data that police and Crown have long been seeking.</p>
<p>(See Professor Geist’s <a href="https://www.theglobeandmail.com/opinion/article-strong-borders-act-privacy-threats-security/">Globe article</a> on the history of this.)</p>
<p>The Criminal Code has long had something called an assistance order, which compels third parties to assist police in executing a warrant. (Open that storage locker please.) The lawful access provisions do the same but on a larger scale.</p>
<p>They impose of obligations on “electronic service providers,” or anyone providing a digital service (storage, creation, or transmission of data) to people in Canada or if situated here, and more onerous obligations on a class called “core providers” who can be added to a schedule to the Act.</p>
<p>An ESP can be ordered to “provide all reasonable assistance, in any prescribed time and manner, to permit the assessment or testing of any device, equipment or other thing that may enable an authorized person to access information”.</p>
<p>But core providers will be subject to regulations that mandate the “installation… of any device, equipment or other thing that may enable an authorized person to access information”.</p>
<p>A core provider might be Google or Meta, Shaw or Telus. And the equipment at issue could enable direct access to accounts, stored files, data logs, and so on.</p>
<p>There are two important limits on this.</p>
<p>One is that police (or an authorized person, such as a CSIS agent) can only go ahead and access data or demand it if they have authority to do so under law — which may or may not involve a warrant, reasonable grounds, and so on.</p>
<p>The other limit applies to both ESPs and core providers: they do not have to follow an order “if compliance… would require the provider to introduce a systemic vulnerability in electronic protections related”. I take this to mean that they cannot be compelled to install a backdoor to encryption.</p>
<p>Are these powers immune to challenge under section 8 of the Charter?</p>
<p>They do not contemplate a search directly. But depending on how an assistance order is used, it could result in an unreasonable search.</p>
<p>For example, a while ago, there was a <a href="https://www.robertdiab.ca/papers/Password.pdf">debate</a> about whether using an assistance order to compel a person to provide police their password might amount to an unreasonable search.</p>
<p>The companies subject to a requirement under this new lawful access statute could challenge it in court — either in response to an order made to them specifically or under a regulation that applies to them as a core provider (on administrative law principles).</p>
<p>But it’s harder to imagine a case where police have conducted a search on lawful grounds, or with a valid warrant, which is found to be unreasonable under section 8 because police were able to gain access to private data more readily through technical means of access made possible under this new statute.</p>
<p>But I can envision two possible exceptions.</p>
<p>One is if the means of access mandated under the new Act amounts to an interception: realtime access to data that police use to obtain the data at issue. An accused person would need to show, however, that police came into possession of their private data in realtime and without a warrant under the wiretap (interception) provisions in Part VI of the Criminal Code. (See the <a href="https://canlii.ca/t/fwq20">Telus</a> case for more on this distinction.)</p>
<p>Another exception is simply that police gained quick access technically, but without a lawful basis (a warrant, etc.).</p>
<p>But it isn’t inconceivable that the Supreme Court might eventually say that mandating certain measures, means, or forms of access amount to an unreasonable search even if used with lawful authority such as a warrant. These might include means that somehow give police with a warrant access to data being created now and in the future, in addition to data already created.</p>
<p>If you’re still with me, thanks for reading! I’ll continue to follow the bill as it makes its way through Parliament and try to post about it here.</p>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/deepresearch/">Testing the waters with Deep Research</a></div>

  
            <span class="post-date">
              Mar 4, 2025
            </span>

          

<p><p>Last month OpenAI unveiled a new tool for producing lengthy reports with citations to sources on the web. It uses one of the company’s best ‘chain of reasoning’ models to deliver output that far exceeds the quality of what similar tools from Google and Perplexity AI can do – tools that are also called ‘Deep Research,’ as it happens.</p>
<p>But initially, OpenAi’s version was only available to folks with the $200 US a month “pro” subscription. We had to take on faith effusive reviews, like this one from <a href="https://www.reddit.com/r/ChatGPTPro/comments/1iis4wy/deep_research_is_hands_down_the_best_research/?rdt=52148">Reddit</a>:</p>
<blockquote>
<p>Deep Research has completely changed how I approach research. I canceled my Perplexity Pro plan because this does everything I need. It’s fast, reliable, and actually helps cut through the noise.</p>
<p>For example, if you’re someone like me who constantly has a million thoughts running in the back of your mind—Is this a good research paper? How reliable is this? Is this the best model to use? Is there a better prompting technique? Has anyone else explored this idea?—this tool solves that.</p>
<p>It took a 24-minute reasoning process, gathered 38 sources (mostly from arXiv), and delivered a 25-page research analysis. It’s insane.</p>
</blockquote>
<p>Not everyone was so enthused. One commentator <a href="https://theconversation.com/openais-new-deep-research-agent-is-still-just-a-fallible-tool-not-a-human-level-expert-249496">noted</a> that it can “miss key details, struggle with recent information and sometimes invents facts.”</p>
<p>The Verge had a <a href="https://www.theverge.com/openai/607587/chatgpt-deep-research-hands-on-section-230">piece</a> about using Deep Research to produce a report on the judicial treatment of section 230 of the Communications Decency Act in the last five years – concluding that “it got the facts right but the story wrong.” Although none of the cases it cited were made-up, and its summary was generally accurate, it had one major problem: it ended in 2023. But 2024 was “a rollicking year for Section 230,” with many important developments, as a law scholar quoted in the article pointed out.</p>
<p>When I first read about OpenAI’s new tool, I was keen to find out whether it could look up sources on third-party databases like <a href="https://www.canlii.org/en/">Canlii</a> or <a href="https://www.jstor.org/">JSTOR</a>. If it could do this, DP would be quite powerful. You could ask it to find a case about X and it would formulate the query, run the search and – most importantly – read through the cases to find the needle in the haystack.</p>
<p>For the moment, however, it doesn’t do this. But OpenAI <a href="https://openai.com/index/introducing-deep-research/">says</a> that accessing databases like Canlii is on its way.</p>
<p>(Incidentally, I’ve been writing about how much better free or almost free AI has become at doing brief overviews of Canadian law. I’ve got a piece on the way documenting how well OpenAI’s reasoning model GPT o1 produced a summary on the law of unjust enrichment in 500 words, which I knew little about. It came up with a cogent summary, with correct citations to the three leading Supreme Court of Canada decisions on point and the main 3-part test to be applied. Check it out <a href="https://chatgpt.com/share/67b5f8be-e58c-8003-8db1-486086423bb5">here</a>.)</p>
<p>The thrust of this post, however, is to report on my own test drive with OpenAI’s Deep Research. As a GPT Plus subscriber (30$ Canadian a month), I gained access to DR only last week but couldn’t think of a good query to test it with. With “plus” users getting only 10 queries a month, I’m inclined to be sparing with them.</p>
<p>Here was my ungrammatical query:</p>
<blockquote>
<p>What uses are being made in Canada to use artificial intelligence in decision-making by government agencies or entities, and what policy statements or guidelines have been issued by government or agencies with respect to this?</p>
</blockquote>
<p>As you may know, before it embarks on a search that can last between about 5 and 30 minutes, it asks you a few questions to sharpen the boundaries. It asked me:</p>
<blockquote>
<p>Are you looking for information on AI use by government agencies across all levels (federal, provincial, municipal), or just at the federal level? Also, would you like details on specific areas of application (e.g., public safety, healthcare, immigration, etc.)? Lastly, are you interested in ethical considerations and public consultations regarding AI in government decision-making?</p>
</blockquote>
<p>I told it to be as inclusive as possible.</p>
<p>What it produced was thoroughly impressive. It took 7 minutes and came back with an 11,000 word document titled “AI in Government Decision-Making in Canada” that cited 27 sources. You can read it <a href="https://chatgpt.com/share/67c5a7b0-6320-8003-bcb2-52e3bb0e7167">here</a>.</p>
<p>It was both informative and sufficiently engaging that I read it all the way through, and I learned an enormous amount. (I then got it to do a 1,000 word summary, which you can find at the end of the thread.)</p>
<p>The report was impressive both in terms of what it covered and where it pointed. It touched on the use of AI at federal, provincial, and municipal levels across Canada and in various fields: policing, healthcare, immigration, social services, transportation, even the courts.</p>
<p>It also struck a nice balance between useful and reliable government policy docs and reports, and shorter news items.</p>
<p>What struck me reading it was that it would take me easily a week of surfing, reading, note-taking, and compiling to produce something this good. Maybe more.</p>
<p>It would no doubt have been a better report. More selective in some ways, more discerning, maybe more probing.</p>
<p>But this was about 70 to 80% as good as I could do myself – <em>in 7 minutes</em>. It hit all the bases, all the major stories in the government use of AI in recent years: Clearview AI, Chinook, interventions by the Federal Privacy Commissioner, major policy statements on the use of AI.</p>
<p>Quibble with this as you might, but this is not a minor development. The sources are real. The general summary is cogent and more or less accurate as far as it goes. Is it missing that great paper by so-and-so on this or that aspect of the problem? No doubt. Does it contain every relevant story, all the relevant policies, cases, and so on. No it doesn’t.</p>
<p>But is it worth consulting <em>as a starting point</em>? Do I know much more about this topic than I did before I ran the query? Absolutely.</p>
<p>I come away from Deep Research feeling more optimistic about the utility of AI in research, and legal research in particular. I can see a point in time on the horizon when AI will produce a better first draft of an outline of argument or opinion than we could possibly do in less than a few days, even with a good grounding in the field.</p>
<p>It’s even to the point of making me question my assumptions about AI not being a substitute for really knowing the law – that people without a solid foundation in law won’t know how to prompt effectively. Just not sure about this any more.</p>
</p>
<br>


<div class=bottomhomelinks>
<a href="/">Back to main page</a> | <a href="/posts">Archive</a>
</div>
</div>


        </div>

    </body>
</html>
