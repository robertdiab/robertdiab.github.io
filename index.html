<!DOCTYPE html>
<html lang="en-us"><head>
	<meta name="generator" content="Hugo 0.81.0" />
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GXV01KRXE5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GXV01KRXE5');
</script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
<meta name="description" content="A blog about technology, rights, and freedoms">


<meta name="keywords" content="technology human rights law policy network internet governance encryption privacy artificial intelligence">


<link rel="stylesheet" media="screen and (min-width: 441px)" href="/css/widescreen.css">

<link rel="stylesheet" media="screen and (max-width: 440px)" href="/css/smallscreen.css">

  <title>Robert Diab</title>

  <link rel="alternate" type="application/rss+xml" href="https://www.robertdiab.ca/index.xml" title="Robert Diab" />
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png">
  <link rel="manifest" href="/images/favicon/site.webmanifest">
  <link rel="mask-icon" href="/images/favicon/safari-pinned-tab.svg">
  <link rel="shortcut icon" href="/images/favicon/favicon.ico">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-config" content="/images/favicon/browserconfig.xml">
  <meta name="theme-color" content="#ffffff">


</head>
<body>
      <div class="hdsection">







<div class="sitelogo-field">
<a href=" / "><img src="/images/nRD90.svg"></a>
</div>














</div>

      <div class="sidenav">









<span class="navtitle">Bio</span><br>

<span class="smallnav"><a href="/about" style="">About</a><br></span>

<span class="smallnav"><a href="/research" style="">Research</a></span><br>

<span class="smallnav"><a href="/writing" style="">Writing</a><br></span>
<br>


<span class="navtitle">Recent posts</span><br>
<span class="smallnav">
<div class=recent-posts>

  

<a href="https://www.robertdiab.ca/posts/crawford-atlas/">Kate Crawford on the Social and Environmental Impact of AI<div class=space> </div></a><br>

  

<a href="https://www.robertdiab.ca/posts/end-of-passwords/">The End of Passwords?<div class=space> </div></a><br>

  

<a href="https://www.robertdiab.ca/posts/icloud-private-relay/">Will iCloud Private Relay Make Us All Anonymous?<div class=space> </div></a><br>

  

  </div>
</span>

<span class="navtitle">Archive</span><br>

<span class="smallnav"><a href="/posts" style="">By date</a></span>
<br>
<span class="smallnav"><a href="/tags/" style="">By topic</a></span>
<br>

<br>
<span class="navtitle">Follow</span><br>

<span class="smallnav"><a href="/index.xml" style="">RSS Feed</a></span><br>

<span class="smallnav"><a href="http://twitter.com/robertdiab" style="">Twitter</a><span><br>
</div>

        <div class="content">

<div class=post-content>

  

<div class=post-title><a href="https://www.robertdiab.ca/posts/state-censorship/">What Can the State Do to Censor the Net? The Case of India</a></div>

  
            <span class="post-date">
              Saturday, Jul 3, 2021
            </span>

          

<p><p>Recent events in India got me thinking about an enduring question in the politics of the internet: how much control do nation states have over the net?</p>
<p>The question ties into a larger debate I&rsquo;ve been pondering (and will explore more in the future): what might be called the Gurri-Deibert debate.</p>
<p>Martin Gurri&rsquo;s <a href="https://www.amazon.ca/Revolt-Public-Crisis-Authority-Millennium-ebook/dp/B07J2V3PG4">work</a> presents the net as a serious if not mortal threat to authoritarian regimes (the paradigm case being the Arab spring), while Ron Deibert&rsquo;s <a href="https://houseofanansi.com/products/reset">work</a> presents it as a tool for unprecedented surveillance and control.</p>
<p>A closer look at India is one of many examples that makes clear the Gurri-Deibert debate can&rsquo;t be settled on a global level <em>easily</em>.</p>
<p>As India shows, the answer to the question of how much of a threat the net poses to a regime, or how much damage a regime can do to fundamental rights using the net, depends on a host of factors.</p>
<p>Among them: the culture of freedom in a given country, the extent of the rule of law or the degree of corruption, and the government&rsquo;s control over institutions.</p>
<p>India is also a good place to begin making sense of the levels of control a country can exert in censoring the net.</p>
<p>European and North American countries generally censor only to protect intellectual property or injury to reputation. And they do so by <a href="https://digitalcommons.osgoode.yorku.ca/ohlj/vol56/iss2/1/">order of a court</a> or a regulatory body that applies a statutory or common law power.</p>
<p>India is a commonwealth country with a strong judiciary and a culture of the rule of law. But the government of Narendra Modi has been keen to repress dissent and criticism of its handling of the pandemic, of labour reform, and other issues.</p>
<p>For example, in April, it <a href="https://www.nytimes.com/2021/04/25/business/india-covid19-twitter-facebook.html">ordered</a> Facebook, Twitter, and Instagram to take down content critical of the government on Covid. As the NY Times reports:</p>
<blockquote>
<p>Squabbles over online speech in India are growing common. The Indian government&hellip; has become increasingly aggressive at stifling dissent. It has arrested activists and journalists, and pressured media organizations to hew to its line. It has cut off mobile internet access in troubled areas. After a standoff with China, it blocked a number of apps owned by Chinese companies.</p>
</blockquote>
<p>What can the Modi government do to quell online dissent, short of shutting down the net altogether?</p>
<p>At least a few things &ndash; pointing to gradations of censorship, short of a full shut down.</p>
<p>According to <a href="https://techcrunch.com/2021/06/07/twitter-restricts-accounts-in-india-to-comply-with-government-legal-request/">TechCrunch</a>, India passed law earlier this year compelling social media companies to &ldquo;acknowledge takedown requests of unlawful, misinformation and violent content within 24 hours and deliver a complete redressal within 15 days.&rdquo; And in &ldquo;sensitive cases such as those surrounding explicit sexual content, firms will be required to take down the content within 24 hours.&rdquo;</p>
<p>All pretty standard so far. That is: pass laws that force private companies to engage in censorship, which works in-country but not beyond it.</p>
<p>Modi may be using these laws aggressively, insisting that legitimate dissent is &ldquo;misinformation&rdquo; under the law. And social media companies can resist demands to remove content by questioning the legality of requests.</p>
<p>But aside from these public arguments, what more could Modi do? How much more control can a state exert?</p>
<p>Due to the level of government scrutiny from civil society groups in India, one would hope the answer is: not much more.</p>
<p>But, in technical terms, the fine work by folks at <a href="https://citizenlab.ca/">CitizenLab</a> in Toronto points us to next steps that other regimes have taken.</p>
<p>As Lex Gill, Jon Penney, and their co-authors have <a href="https://citizenlab.ca/2018/04/planet-netsweeper/">shown</a>, governments have used software from private companies like Canada&rsquo;s Netsweeper Inc. to filter net content in countries that include Afghanistan, Bahrain, India, Kuwait, Pakistan, Qatar, Somalia, Sudan, UAE, and Yemen. (See also CitizenLab&rsquo;s <a href="https://citizenlab.ca/2018/03/bad-traffic-sandvines-packetlogic-devices-deploy-government-spyware-turkey-syria/%E2%80%8B">report</a> on the use of tech by San Franciso&rsquo;s Sandvine Inc. in Turkey and Egypt.)</p>
<p>Governments in these cases contract with private companies for technology involving &lsquo;deep packet inspection.&rsquo; A <a href="https://dspace.library.uvic.ca/bitstream/handle/1828/5024/Parsons_Christopher_PhD_2013.pdf?sequence=6&amp;isAllowed=y%E2%80%8B">doctoral thesis</a> by Christopher Parsons (also at CitizenLab) from 2013 is informative on how DPI works and how it can impact fundamental freedoms.</p>
<p>As Parson&rsquo;s explains, a government or internet service provider (acting at the gov&rsquo;s direction) can deploy a &lsquo;DPI appliance&rsquo; to intercept or &ldquo;‘close’ transmissions by informing the applications on peoples’ computers that the transmission has failed.&rdquo; It can also be used to monitor the web for types of communication and to make copies of the data sent and received.</p>
<p>As Milton Mueller has <a href="https://pdfs.semanticscholar.org/17d8/e798bacba1d93f72d09c03f53857cd62222e.pdf%E2%80%8B">noted</a>, DPI helps governments do a number of things to control the flow of traffic online: manage bandwidth, profile users, surveil, and police for copyright or content.</p>
<p>In short, there are levels of control short of China&rsquo;s <a href="https://hir.harvard.edu/building-the-fire-wall/">Great Firewall</a>. And how measures are deployed, and against whom, depends in large part on the regime, the population, and its politics.</p>
<p>This settles nothing about the Gurri-Deibert debate, but it&rsquo;s a good place to start.</p>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/crawford-atlas/">Kate Crawford on the Social and Environmental Impact of AI</a></div>

  
            <span class="post-date">
              Monday, Jun 14, 2021
            </span>

          

<p><p>I’m reading and learning a lot from Kate Crawford’s <a href="https://yalebooks.yale.edu/book/9780300209570/atlas-ai">Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence</a> (Yale, 2021). It might be grouped with earlier books that give us a glimpse of the underside of computing, the hidden material conditions. Books like Andrew Blum’s <a href="https://www.andrewblum.net/tubes-2">Tubes: A Journey to the Centre of the Internet</a> (Ecco, 2012) or Tung-Hui Hu’s <a href="https://mitpress.mit.edu/books/prehistory-cloud">A Prehistory of the Cloud</a> (MIT, 2015).</p>
<p>Crawford’s title is misleading. It’s not a book about artificial intelligence; it’s about computation in the abstract — all forms of it: PC, mobil, mainframe, network, etc. She’s concerned with planetary environmental and social costs that remain hidden in much of our experience of technology, and in the stories of progress we tell about it. Her thesis (from the Introduction):</p>
<blockquote>
<p>I argue that AI is neither artificial nor intelligent. Rather, artificial intelligence is both embodied and material, made from natural resources, fuel, human labor, infrastructures, logistics, histories, and classifications. AI systems are not autonomous, rational, or able to discern anything without extensive, computationally intensive training with large datasets or predefined rules and rewards. In fact, artificial intelligence as we know it depends entirely on a much wider set of political and social structures. And due to the capital required to build AI at scale and the ways of seeing that it optimizes AI systems are ultimately designed to serve existing dominant interests. In this sense, artificial intelligence is a registry of power.</p>
</blockquote>
<p>Crawford sees AI (or computation) as the product of a series of “economic, political, cultural, and historical forces”. Her aim is to “connect AI within these broader structures and social systems,”  so as to “escape the notion that artificial intelligence is a purely technical domain.”</p>
<blockquote>
<p>At a fundamental level, AI is technical and social practices, institutions and infrastructures, politics and culture. Computational reason and embodied work are deeply interlinked: AI systems both reflect and produce social relations and understandings of the world.</p>
</blockquote>
<p>As to why she chose the metaphor of an atlas as a framework, Crawford explains:</p>
<blockquote>
<p>By invoking an atlas, I’m suggesting that we need new ways to understand the empires of artificial intelligence. We need a theory of AI that accounts for the states and corporations that drive and dominate it, the extractive mining that leaves an imprint on the planet, the mass capture of data, and the profoundly unequal and increasingly exploitative labor practices that sustain it. These are the shifting tectonics of power in AI. A topographical approach offers different perspectives and scales, beyond the abstract promises of artificial intelligence or the latest machine learning models. The aim is to understand AI in a wider context by walking through the many different landscapes of computation and seeing how they connect.</p>
</blockquote>
<p>I’m only through two of the chapters thus far. The one on the environmental impact of AI’s tendency toward ‘extraction’ was eye-opening. Producing a laptop battery, let alone one for a Tesla or a Ford 150, involves an enormous amount of permanent waste and destruction through lithium mining. But it&rsquo;s in keeping, as Crawford shows, with a long tradition of network tech doing serious environmental damage that extends at least as far back as the telegraph.</p>
<p>The chapter on labour draws interesting parallels between “the repetitive motions of robots and line machinery” and the “controlling of bodies in space and time” in the work farmed out to gig workers by Amazon, Facebook, and others.</p>
<p>Other chapters explore data harvesting in AI, prediction algorithms, and their use in state power. As a bonus, Crawford writes with journalistic flair and moves fluidly through well-chosen historical anecdotes. Can’t put it down.</p>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/end-of-passwords/">The End of Passwords?</a></div>

  
            <span class="post-date">
              Saturday, Jun 12, 2021
            </span>

          

<p><p>In developer builds of its system updates, Apple is testing the new WebAuthn passkey standard.</p>
<p>I suspect I&rsquo;m not alone in hoping that, once it’s out of beta, it will make passwords obsolete, for the most part.</p>
<p>Stephen Shankland at <a href="https://www.cnet.com/news/apple-says-its-new-logon-tech-is-as-easy-as-passwords-but-far-more-secure/">CNET</a>:</p>
<blockquote>
<p>To set up an account on a website or app using a passkey, you first choose a username for the new account, then use FaceID or Touch ID to confirm that it&rsquo;s really you who&rsquo;s using the device. You don&rsquo;t ever pick a password. Your device handles generation and storage of the passkey, which iCloud Keychain synchronizes across all your Apple devices. […]</p>
<p>The tech behind Apple&rsquo;s passkeys is built on the WebAuthn technology that emerged from the <a href="https://fidoalliance.org">FIDO (Fast Identity Online) Alliance</a>, a consortium that&rsquo;s been overhauling authentication with hardware security keys. Apple&rsquo;s approach embraces a fundamental part of WebAuthn, the combination of public and private encryption keys that&rsquo;s already built deeply into communication security and many other established processes.</p>
</blockquote>
<p>As this helpful <a href="https://webauthn.guide">WebAuthn Guide</a> explains, the new standard:</p>
<blockquote>
<p>…allows servers to integrate with the strong authenticators now built into devices, like Windows Hello or Apple’s Touch ID. Instead of a password, a private-public keypair (known as a credential) is created for a website. The private key is stored securely on the user’s device; a public key and randomly generated credential ID is sent to the server for storage. The server can then use that public key to prove the user’s identity.</p>
<p>The public key is not secret, because it is effectively useless without the corresponding private key. The fact that the server receives no secret has far-reaching implications for the security of users and organizations. Databases are no longer as attractive to hackers, because the public keys aren’t useful to them.</p>
</blockquote>
<p>Whether Apple will roll this out in the fall is unclear. But soon, they will, along with other members of the FIDO alliance behind the WebAuthn standard, including Google and Microsoft.</p>
<p>It’s nice to see encryption used in this new way to make something so fundamental to our use of the web both more convenient and more secure. It&rsquo;s rare that we get both.</p>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/icloud-private-relay/">Will iCloud Private Relay Make Us All Anonymous?</a></div>

  
            <span class="post-date">
              Friday, Jun 11, 2021
            </span>

          

<p><p>Apple has unveiled a new feature, on mobile platforms and the Mac, that offers more privacy than a VPN and more speed than Tor networks.</p>
<p>I assume this will lead to a quantum leap in the amount of traffic online that becomes anonymous &ndash; for reasons that have to do with both the convenience and the ingenuity of Apple&rsquo;s solution to this long-standing problem.</p>
<p>Until now, the most common options for concealing your tracks on the web were to use a virtual private network or Tor (an open source app involving a series of relay servers around the world).</p>
<p>A VPN would shield your identity from your ISP or the sites you visit, but not from the VPN provider itself. You would have to trust the VPN with your info, or hope it wouldn’t be hacked. Using a Tor browser spared you from having to share info with a VPN, but the relay process that concealed your IP address made surfing slow and cumbersome.</p>
<p>The novelty of iCloud Private Relay is that no one has all the info necessary to tie your browsing history to your device or identity. Apple’s clever solution is to use a middleman, an unnamed set of ‘trusted content providers.’ You give certain information to Apple’s servers and they turn over <em>some</em> of it to another set of servers that speak to the sites you wish to visit.</p>
<p>As Dave Hamilton at <a href="https://www.macobserver.com/tips/deep-dive/digging-into-apples-icloud-private-relay/">the Mac Observer</a> puts it: “Apple doesn’t know what site(s) you’re visiting, and the third-party content provider doesn’t know who you are.”</p>
<p>And in contrast to Tor, iCloud Private Relay doesn&rsquo;t cause a noticeable slow down — according to early tests by Hamilton and <a href="https://www.fastcompany.com/90643627/apple-privacy-wwdc-private-relay-vpn-icloud-plus-macos-monterey">others</a>.</p>
<p>iCloud Private Relay is not a standard feature, but a paid add-on through iCloud Plus. But many people will have it, turn it on and forget it&rsquo;s there.</p>
<p>What will it mean that much more traffic will now be concealed more effectively than before? Will it make any difference?</p>
<p>At least one comes to mind: closing down a major avenue for ad-tracking.</p>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/epic-v-apple/">Epic vs Apple and the Search for the Right Analogy</a></div>

  
            <span class="post-date">
              Thursday, May 27, 2021
            </span>

          

<p><p>As often happens in court cases in involving cyberspace, it all comes down to finding the right analogy.</p>
<p>Kyle Orland, following the case closely for <a href="https://arstechnica.com/gaming/2021/05/the-epic-v-apple-case-could-hinge-on-the-definition-of-the-marketplace/">Ars Technica</a>, says it turns on two issues: &ldquo;What is the relevant competitive market and what should the court do if Apple is found to be unfairly monopolizing that market?&rdquo;</p>
<p>Epic’s case hinges on an analogy between Apple’s restrictive practices on its iOS App Store (a 30% cut, no-steering provisions, etc.) and what happened in a well-known case from US Supreme Court in 1992.</p>
<p>In <em>Eastman Kodak Co. v. Image Technical Servs., Inc.</em>, the Court held that despite Kodak not being a dominant player in the market for photocopiers (like Apple in phones), its behaviour in the market for repair parts — restricting supply, forcing customers to buy exclusively from Kodak — was unlawfully anti-competitive.</p>
<p>But Apple says: no, that’s not the right analogy. Yes, it’s true that people who want to buy apps on their iPhones or iPads are forced to use the App Store (in contrast to the Mac, where you can get apps from App Store <em>and also</em> from elsewhere). But iPhone customers are not like Kodak customers. If they want access to the app in question, they can simply use a different device — an Android, an Xbox, etc.</p>
<p>The relevant market, says Apple, is the whole field of device platforms competing for the world’s gamers or users.</p>
<p>No, says Epic, the relevant market is the billion or so people in the world who use an iPhone, and Apple holds them hostage just as Kodak did by wiping out the aftermarket for parts.</p>
<p>Are Apple’s customers like Kodak’s customers? Or are they in a fundamentally different position?</p>
<p>Conceding this to be a central question, one of Apple’s lawyers asserted: “This is not a case where there’s one device out there and if there’s a part missing you’re out of luck, you can&rsquo;t use that device…”</p>
<p>Ben Thompson <a href="https://stratechery.com/2021/app-store-arguments/">points out</a> that appellate decisions have narrowed the scope of <em>Eastman Kodak</em> to cases where customers don’t know they’re buying into a walled garden when they buy a product — and that if they do know and still freely to choose to buy the product, the company is free to reap benefits from its monopolistic position (charging higher fees, setting rules), but it cannot be anti-competitive. The company can&rsquo;t prevent other parties from offering competing products and services.</p>
<p>Which brings us back to the question of analogy.</p>
<p>If people aren’t likely to leave the Apple ecosystem to use their favourite apps on other devices — because it’s ever harder to leave once you’re in Apple’s walled garden — are its customers not like those of Kodak? Sure, they bought their iPhone knowing it would entail submitting to Apple’s monopoly on app purchases, but did they have a real choice?</p>
<p>I wouldn’t be surprised if Judge Gonzales Rogers — explicitly or impliedly — sees the App Store as more like the Kodak case than not and forces Apple to give users and developers some measure of choice here they didn’t have before.</p>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/compelled-discoverability/">Canada&rsquo;s Plan for Compelled Discoverability</a></div>

  
            <span class="post-date">
              Monday, May 17, 2021
            </span>

          

<p><p>Canada may soon be the first country to pass law compelling platforms like Youtube and Tik Tok to make content created by domestic users more discoverable. Surely this can’t be constitutional, you might think.</p>
<p>There are passionate voices arguing both sides of the question, but they appear to be talking  past one another.</p>
<p>To be more precise, Bill C-10 wouldn’t compel discovery directly; it would empower the country’s broadcast authority, the Canadian Radio-television and Telecommunications Commission, to do so. This would bring Youtube and friends under the regulatory fold along with an older and very different set of entities.</p>
<p>To make a case that a law forcing YouTube to feature Canadian content in search results (or forcing Tik Tok to curate content streams, etc) is unconstitutional under Canada&rsquo;s <em>Charter of Rights and Freedoms</em>, a challenger would need to establish two things: (1) that such a law violates either a user’s freedom of expression or that of the platform itself; and (2) that the violation is not a reasonable limit on the freedom.</p>
<p>The case for violating free expression would rest on a long-standing claim that search index results are a form of speech. It’s a <a href="https://robertmarksimpson.com/assets/pdfs/Search-Engines.pdf">contested</a> claim, but not one that Canadian courts have outright dismissed.</p>
<p>It would seem plausible to me to characterize what happens when I use Youtube as a kind of conversation. I express a preference in my search patterns; Youtube responds by serving me a curated set of choices.</p>
<p>Canada’s courts have <a href="https://scc-csc.lexum.com/scc-csc/scc-csc/en/item/1835/index.do">suggested</a> that free expression includes not only the right to say something but also the right to hear it. On this basis, an interruption in the conversation I have with YouTube violates the rights of both parties.</p>
<p>But people in favour of the Bill insist that there’s no interruption in compelling discoverability. On Monday, Janet Yale, head of the Broadcasting and Telecommunications Legislative Review panel, <a href="https://nationalpost.com/news/politics/its-about-promotion-of-canadian-choices-academics-argue-that-bill-c-10-does-not-impede-freedom-of-speech">told</a> a parliament committee on the bill:</p>
<blockquote>
<p>…it’s not about interfering with freedom of choice, it’s about promotion of Canadian choices … Nobody has to watch it if they don’t want to watch it. So there is actually no restriction on freedom of choice whatsoever.</p>
</blockquote>
<p>She’s wrong because the interference lies not in being forced to watch but in having the choice of what to watch interfered with. When I ask YouTube to show me content on X topic, I want the best videos in the world on X, not the best videos that happen to be Canadian.</p>
<p>Establishing a case for violating free expression does not seem too difficult. The fuzzier part comes in trying to predict whether a court (possibly our highest) will think this kind of limit on our rights is justified. Part of the analysis will turn on whether compelled discoverability advances a “pressing and substantial objective”.</p>
<p>The <a href="https://audiencelab.fcad.ryerson.ca/wp-content/uploads/2019/05/YouTube-Full-Report-FINAL_V7_May21.pdf">evidence</a> would seem to be clear that Canadian creators are doing exceedingly well on YouTube — including French Canadians &ndash; with many among the most popular in their various niches. The reasonable limit case may be hard for the government to make out.</p>
<p>But we’ll have to wait for the lengthy, costly, and almost certainly inevitable litigation to find out.</p>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/governance-by-data/">Governance by Data</a></div>

  
            <span class="post-date">
              Thursday, May 13, 2021
            </span>

          

<p><p>Fleur Johns was kind enough to send me a pre-print copy of her new article “<a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-lawsocsci-120920-085138">Governance by Data</a>” in the <em>Annual Review of Law and Social Science</em>. From the abstract:</p>
<blockquote>
<p>Law and social science scholars have long elucidated ways of governing built around state governance of populations and subjects. Yet many are now grappling with the growing prevalence of practices of governance that depart, to varying degrees, from received models. The profusion of digital data, and the deployment of machine learning in its analysis, are redirecting states’ and international organizations’ attention away from the governance of populations as such and toward the amassing, analysis, and mobilization of hybrid data repositories and real-time data flows for governance. Much of this work does not depend on state data sources or on conventional statistical models. The subjectivities nurtured by these techniques of governance are frequently not those of choosing individuals. Digital objects and mediators are increasingly prevalent at all scales.</p>
</blockquote>
<p>The essay makes the larger and persuasive point that the impact of data collection and use by the state is more subtle and profound in its effects on us, in many ways, than are the algorithms of our favourite platforms.</p>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/politics-recognition-social-media/">The Politics of Recognition in the Age of Social Media</a></div>

  
            <span class="post-date">
              Thursday, May 13, 2021
            </span>

          

<p><p>William Davies, <a href="https://newleftreview.org/issues/ii128/articles/william-davies-the-politics-of-recognition-in-the-age-of-social-media">writing</a> in the latest issue of the <em>New Left Review</em>, explores how “transformations in the public sphere have led to a mutation in how recognition” of cultural, racial, or political identity “is demanded and supplied”:</p>
<blockquote>
<p>The key condition for this is the digital platform, which has ushered in a new era of public participation in which recognition of status is never adequately achieved by anyone, so injustice feels ubiquitous. In the attention economy of social media, public actors may long for recognition, but have to settle instead for varying quantities of ‘reputation’, or simply the ‘reaction’ of immediate feedback.</p>
</blockquote>
<p>The essay contains a thoughtful discussion of theories of recognition: Charles Taylor, Nancy Fraser, Alex Honneth. It also lends insight into how the “public sphere under platform capitalism differs from that of print capitalism”:</p>
<blockquote>
<p>…public discourse is never divorced from the identity and status of the participants, save where identity is deliberately disguised as a political tactic, for trolling. An exchange on a platform leaves a trace, which remains attached to the digital identity of both parties, and serves as a type of investment (positive or negative) in their reputations. Opinion, judgement and critique no longer exist in any autonomous form, but become mediators of social relations and investments.</p>
</blockquote>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/what-comes-after-the-internet/">What Comes After the Internet</a></div>

  
            <span class="post-date">
              Thursday, May 13, 2021
            </span>

          

<p><p>Matthew Ball on the coming <a href="https://www.matthewball.vc/all/themetaverse">Metaverse</a>:</p>
<blockquote>
<p>…the Metaverse has become the newest macro-goal for many of the world’s tech giants. As I outlined in February of 2019, it is the express goal of Epic Games, maker of the Unreal Engine and Fortnite. It is also the driver behind Facebook’s purchase of Oculus VR and its newly announced Horizon virtual world/meeting space, among many, many other projects, such as AR glasses and brain-to-machine communications. The tens of billions that will be spent on cloud gaming over the next decade, too, is based on the belief that such technologies will underpin our online-offline future.</p>
</blockquote>
<p>Among its key features, Ball speculates, are persistence; synchronicity; concurrent participation across space; a straddling of online and offline worlds, open and closed platforms; and “unprecedented interoperability of data, digital items/assets, content, and so on across each of these experiences”.</p>
<p>The metaverse is not to be confused with “virtual reality”, “virtual space,” a game, or even “online experience itself”.</p>
<p>It will depend on a number of developments, including a greater &ldquo;concurrency infrastructure&rdquo; to host ever larger, mass, real-time events online; a more robust and resilient set of standards and protocols, narrowing the number of common file formats; and a more inviting set of “on-ramp experiences” to the ones that brought us online in the late 90s.</p>
<p>A fascinating vision of at least some of the changes at a macro level that we can expect to see in the evolution of digital and network tech in the coming decade or two.</p>
<p>One insight, among many, that stands out here:</p>
<blockquote>
<p>&hellip;it won’t directly come into existence; there will be no clean “Before Metaverse” and “After Metaverse”. Instead, it will slowly emerge over time as different products, services, and capabilities integrate and meld together.</p>
</blockquote>
</p>
<br>


<div class=post-title><a href="https://www.robertdiab.ca/posts/uptake-police-bodycams/">Police Bodycam Use About to Rise in Canada</a></div>

  
            <span class="post-date">
              Monday, Apr 26, 2021
            </span>

          

<p><p>After years of reluctance by police and government in Canada to embrace bodycams, Colin Freeze reports that things are beginning to change.</p>
<p>His informative <a href="https://www.theglobeandmail.com/canada/article-police-are-increasingly-sold-on-bodycam-technology/">piece</a> (behind a paywall at the Globe) notes a series of changes on the ground across Canada in the wake of George Floyd&rsquo;s murder, captured on video last summer.</p>
<p>Soon after that occurred, Trudeau announced $50 million in funding for RCMP bodycams. Forces in Ontario have recently announced $70 million in contracts, with two of the province&rsquo;s largest forces &ndash; Peel and Toronto &ndash; budgeting $10 and $34 million respectively for body-worn cameras.</p>
<p>As Freeze points out, Canada lacks law regulating the use of bodycams, giving rise to a host of issues:</p>
<blockquote>
<p>Police forces that do have them must create their own policies on when video can be released. In cases of videotaped deaths and injuries, the decision will lie with provincial watchdog bodies such as Ontario’s Special Investigative Unit – which currently take months to investigate before releasing any findings.</p>
</blockquote>
<p>A forthcoming <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3623440">article</a> in <em>Criminal Law Quarterly</em> that I co-authored with Marshall Putnam argues for <em>Criminal Code</em> amendments that would guide police and prosecutors in the use of camera evidence &ndash; when to record, disclosure, privacy, etc.</p>
<p>Without codifying rules in federal law, we suggest, camera uptake and use in Canada will be a confusing patchwork of law and practice, with unfair, inefficient outcomes.</p>
</p>
<br>


<div class=bottomhomelinks>
<a href="/">Back to Top</a> | <a href="/posts">Archive</a> | <a href="/about">About</a>
</div>
</div>


        </div>

    </body>
</html>
